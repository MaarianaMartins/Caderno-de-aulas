{
  "hash": "228c20dd0679241c097061a2db74422d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Aula 9- experimento fatorial e ajuste de modelos\"\nformat: html\neditor_options: \nmessage: false \nwarning: false\n---\n\n\n# Importação de dados\n\nPodridão de Fusarium em milho Parcela subdividida. Dentro de cada bloco foi casualizado os híbridos. O método de aplicação foi casualizado dentro dos híbridos\n\nModelo misto: fator fixo + fator aleatório\n\nExperimento fatorial, DBC com parcela subdividida (4 blocos, aleatorizando a parcela princial dentro de cada bloco, nesse caso foi o híbrido, cada um dentro de cada bloco. O bloco é subdividido e aleatorizado com o método dentro de cada bloco. Sorteia o híbrido e sorteia a posição de cada método). Duas opções: usar lm ou aov, ou usar o modelo misto (quando tem uma mistura de um fator fixo e um fator aleatório do modelo, tem que considerar o efeito aleátorio do híbrido dentro do bloco e do método no híbrido).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nlibrary(tidyverse)\n\nmilho <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n```\n:::\n\n\n## Visualizar dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho |> \n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.1, color = \"black\", alpha = 0.2)+\n  facet_grid(~hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#Dependendo do híbrido parece que há efeito do método\n\nmilho |> \n  ggplot(aes(method, yield))+\n  geom_jitter(width = 0.1, color = \"black\", alpha = 0.2)+\n  facet_grid(~hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"red\")\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\n## Modelo para parcela subdividida - index\n\nNa ANOVA pode ser observado que a interação entre o híbrido e o método é significativo, a partir dai temos que fazer os desdobramentos dessa interação. Pacote para estimar as médias -\\> emmeans\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\n\nmilho <- milho |> \n  mutate(block = as.factor(block))\n\nmix <- lmer(index ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\n\nlibrary(car)\nAnova(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(>Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n#Pelo menos um híbrido é diferente dos demais, assim como existe diferença significativa entre métodos.\n#Também existe diferença na interação híbrido com método\n\nlibrary(performance)\ncheck_normality(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.635).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n```\n\n\n:::\n\n```{.r .cell-code}\n#Observou heterogeneicidade das variâncias\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix))\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#Transformação com raiz quadrada\nmix2 <- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\nAnova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(>Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0718  3   0.994997   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.440).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.971).\n```\n\n\n:::\n\n```{.r .cell-code}\n#Deu distribuição normal e homocedasticidade\nplot(simulateResiduals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-3-4.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)\nmedias_milho <- emmeans(mix2,\n                        ~hybrid|method,\n                        type = \"response\") #Qaundo transforma dados, precisa colocar type = response\nmedias_milho\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n```\n\n\n:::\n\n```{.r .cell-code}\nmedias_milho2 <- emmeans(mix2,\n                         ~method|hybrid,\n                         type = \"response\")\nmedias_milho2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_milho, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_milho2, Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n## Modelo para parcela subdividida - yield\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix3 <- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\n\nAnova(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(>Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n#Pelo menos um híbrido é diferente dos demais, assim como existe diferença significativa entre métodos.\n#Também existe diferença na interação híbrido com método\n\nlibrary(performance)\ncheck_normality(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.214).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.686).\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)\nmedias_milho3 <- emmeans(mix3,\n                        ~hybrid|method,\n                        type = \"response\") #Qaundo transforma dados, precisa colocar type = response\nmedias_milho\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n```\n\n\n:::\n\n```{.r .cell-code}\nmedias_milho4 <- emmeans(mix3,\n                         ~method|hybrid,\n                         type = \"response\")\nmedias_milho2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_milho3, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  A    \n 30S31H       8081 743 26.1     6626     9681  AB   \n 30F53 YH     9314 798 26.1     7746    11027  ABC  \n 30F53 HX    11130 872 26.1     9410    12995   BC  \n 30K64       11666 893 26.1     9903    13574    C  \n BG7049H     11914 903 26.1    10131    13841    C  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  A    \n 30F53 YH     9079 788 26.1     7532    10770  A    \n 30S31H       9135 790 26.1     7583    10832  A    \n 30F53 HX     9932 824 26.1     8311    11698  AB   \n 30K64       10331 840 26.1     8676    12131  AB   \n BG7049H     12822 936 26.1    10970    14818   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_milho4, Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  a    \n pin       11130 872 26.1     9410    12995   b   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  a    \n pin        9314 798 26.1     7746    11027  a    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  a    \n pin       11666 893 26.1     9903    13574   b   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  a    \n silk       9135 790 26.1     7583    10832   b   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  a    \n silk       8257 751 26.1     6785     9873  a    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  a    \n silk      12822 936 26.1    10970    14818  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n# Regressão linear\n\nExperimento feito com a inoculação de patogenos nas sementes de arroz. 3%, 12%, 24% e 48%. A hipotése é que conforme aumenta o inoculo do patogeno, diminui o estande de plantas, feito em locais (anos) diferentes. É uma variável númerica contínua, qual a tendência? o padrão? será que tem efeito positivo ou negativo? Espera-se que o número de plantas vai diminuindo. Quer saber a consistência dos resultados em épocas diferentes. X o tratamento, y o número de plantas Geom_smooth faz a linha da regressão linear, indica uma taxa de redução entre os experimentos. Foi mais inclinada onde teve uma maior variação entre as taxas. Mostra que há efeito da inoculação do fungo bipolaris oryzae em arroz, causando redução do estande de plantas conforme aumenta o inoculo. Será que a taxa de redução é significativa? Será que -0,24 é diferente de 0? Tem que olhar o valor do coeficiente estimado do tratamento. Olhando o p-valor do modelo linear, percebe-se que não há diferença, aceita a hipotese nula e assume que o tratamento não tem efeito. Para o experimento 1. Para o experimento 2, rejeita a H0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nestande |> \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.1, color = \"gray\")+\n  facet_wrap(~exp)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")+\n  geom_smooth(method = \"lm\", se = F) #se = F tira a banda de confiança\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nestande |> \n  ggplot(aes(trat, nplants, color = factor(exp)))+\n  geom_jitter(width = 0.1, color = \"gray\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")+\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n```{.r .cell-code}\nexp1 <- estande |> \n  filter(exp == 1)\n\nexp1 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = F)\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-6-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#Modelo Linear\nlm1 <- lm(nplants ~ trat,\n          data = exp1)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,\tAdjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n```\n\n\n:::\n\n```{.r .cell-code}\n#Taxa de redução é -0.24 (quase 25%) - para cada unidade de x reduz o y em -0.24\n#Não rejeita a hipótese nula (a taxa de redução não é diferente de 0)\n\n\n#Fazendo o mesmo para experimento 2\nexp2 <- estande |> \n  filter (exp == 2)\n\nexp2 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = lm, se = F)\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-6-4.png){width=672}\n:::\n\n```{.r .cell-code}\nlm2 <- lm(nplants ~ trat,\n          data = exp2)\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n\n\n:::\n\n```{.r .cell-code}\n#Taxa de redução é -0.70 - para cada unidade de x reduz o y em -0.70\n#Rejeita hipótese nula\n\n#Mesmo para o experimento 3\nexp3 <- estande |> \n  filter (exp == 3)\n\nexp3 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = lm, se = F)\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-6-5.png){width=672}\n:::\n\n```{.r .cell-code}\nlm3 <- lm(nplants ~ trat,\n          data = exp3)\nsummary(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n\n\n:::\n\n```{.r .cell-code}\n#Coeficiente de determinação (adjusted R-squared): 59% da variabilidade do Y (número de plantas) é explicado pelo X (inóculo)\n#O máximo desse coeficiente é 1\n\nresiduals(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          1           2           3           4           5           6 \n  5.2500000  -1.7500000  -2.7500000   9.2500000  -0.4596774   3.5403226 \n          7           8           9          10          11          12 \n  2.5403226  15.5403226   7.8306452   3.8306452 -17.1693548  -2.1693548 \n         13          14          15          16          17          18 \n 12.4112903  -7.5887097  -2.5887097 -26.5887097 -10.4274194  -9.4274194 \n         19          20          21          22          23          24 \n  3.5725806   6.5725806 -10.1048387  19.8951613   1.8951613  -1.1048387 \n```\n\n\n:::\n\n```{.r .cell-code}\nhist(residuals(lm3))\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-6-6.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(lm2))\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-6-7.png){width=672}\n:::\n\n```{.r .cell-code}\n#Se transformar o log dos tratamentos, os dados ficarão mais linearizado (diminui a curva)\nexp2 |> \n  ggplot(aes(log(trat), nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = F)\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-6-8.png){width=672}\n:::\n\n```{.r .cell-code}\n#Outra alternativa é realizar o glm (modelo linear generalizado)\nglm1 <- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp1)\nsummary(glm1) #A família gaussiana é o mesmo que o método \"lm\", resulta em taxa de redução -0.24 tbm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nglm2 <- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp2)\nsummary(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 194.9597\n```\n\n\n:::\n\n```{.r .cell-code}\nglm2b <- glm(nplants ~ trat,\n             family = poisson(link = \"log\"),\n             data = exp2)\nsummary(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.134189   0.037583 110.003  < 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210.2353\n```\n\n\n:::\n\n```{.r .cell-code}\nglm3 <- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp3)\nsummary(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 185.0449\n```\n\n\n:::\n\n```{.r .cell-code}\nglm3b <- glm(nplants ~ trat,\n             family = poisson(link = \"log\"),\n             data = exp3)\nsummary(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3b) #melhor qualidade de ajuste, quanto menor é melhor (mais ajustado)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 183.9324\n```\n\n\n:::\n:::\n\n\n#Como fazer a comparação entre diferentes modelos, usando os mesmos dados. Linera. Poisson. Quanto menor o valor de AIC melhor é. O modelo de poisson é melhor para o experimento 3, por que o AIC deu um valor menor, o que significa que o modelo de ajuste é melhor usar o poisson.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nglm4 <- glmer(nplants ~ trat + (trat|exp),\n            family = \"gaussian\",\n            data = estande)\nsummary(glm4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 592.8402\n```\n\n\n:::\n\n```{.r .cell-code}\nglm4b <- glmer(nplants ~ trat + (trat|exp),   #(trat|exp) é o efeito aleatório\n             family = poisson(link = \"log\"),\n             data = estande)\nsummary(glm4b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.223397   0.147793  28.577  < 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm4b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 660.7282\n```\n\n\n:::\n\n```{.r .cell-code}\n#Pegando os dados de maneira geral, o gaussiano é melhor (menor AIC)\n#Desse modo podemos usar o gaussiano\n```\n:::\n\n\nPara prever a produtividade em função da incidência do mofo branco Relação entre variáveis respostas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"Icens\")\n\nremotes::install_github(\"emdelponte/r4pde\")\nlibrary(r4pde)\n\nwm <- WhiteMoldSoybean\n\nwm |> \n  ggplot(aes(inc, yld, group = factor(study)))+\n  geom_point()+\n  #facet_wrap(~ study)+\n  geom_smooth(method = \"lm\", se = F)+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmofo1 <- lm(yld ~ inc,\n            data = wm)\nsummary(mofo1) #Modelo global\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n\n\n:::\n\n```{.r .cell-code}\n#Intercept é a produtividade com incidência 0\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nmofo2 <- wm |> \n  group_by(study) |> \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\nmofo2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\ndf<- mofo2 |> \n  filter(term == \".$inc\")\nmean(df$estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -19.52932\n```\n\n\n:::\n\n```{.r .cell-code}\n#Histograma da produtividade quando incidência é 0\np1 <- mofo2 |> \n  filter(term == \"(Intercept)\") |> \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Intercept\", y = \"frequency\")\np2 <- mofo2 |> \n  filter(term == \".$inc\") |> \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Slopes\", y = \"frequency\")\nlibrary(patchwork)\np1+p2\n```\n\n::: {.cell-output-display}\n![](Aula9_quarto_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmofo3 <- lmer(yld ~ inc + (inc|study), data = wm, REML = F)\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\n#Esta estimativa é muito mais confiável\n# Inc do efeito fico sendo -17 é mais confiável, os outros métodos subestimam os valores\n#A incidência está causando uma redução na produtividade de -17kg (à medida que a incidência aumenta, a produtividade diminui em 17kg)\n\nAnova(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(>Chisq)    \ninc 141.09  1  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nconfint(mofo3, method = \"Wald\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}