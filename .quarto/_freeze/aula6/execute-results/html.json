{
  "hash": "dc2c7b025d27091f11225326423494ea",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Aula 6 e 7- Estatística inferencial: ANOVA e teste de médias\"\nformat: html\neditor: visual\nmessage: false \nwarning: false\n---\n\n\n#Hoje iremos trabalhar com a estatística inferencial \\$ usado para puxar o dado de uma coluna dentro daquele conjunto de dados; \\~ usar um fator em função do outro.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nmg <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n```\n:::\n\n\n#Visualização dos dados Para esse conjunto de dados, nós temos um fator e dois níveis do fator (com e sem Mg). Efeito do magnésio reduzindo o tamanho da lesão, a aplicação de magnésio está induzindo uma reação de indução de resistência. O tamanho da lesão se encontra maior no tratamento controle. Para publicar esse trabalho, precisa testar uma hípotese \"com a suplementação de magnésio nós temos uma redução do tamanho da doença\" (hípotes experimental), e a hípotes nula nos diz que as médias não diferem (hípotese estatística). No gráfico, vemos um box bem simétrico e uma boa diferença entre as medianas, demonstrando que há possibilidade de existir a diferença.Já da uma indicativa de normalidade por causa da simetria do box, por isso é indicado para muitos tratamentos pela facilidade de visualização.\\\nPara verificar a diferença ou não, usaremos o teste t (teste mais simples, geralmente utilizado com dois grupos, se estiver a mais temos que fazer uma comparação par a par) uma vez que temos poucos tratamentos, assumindo que existe normalidade dos dados e homogeinidade entre as variâncias. 10 plantas que recebem um tratamento e 10 plantas que recebem outro, o que as torna variáveis independentes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nmg |> \n  ggplot(aes(trat,comp)) + \n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n#Realizar a estatística Para usar o teste t nós precisamos dos vetores separados. Uma vez que o conjunto está no formato longo, precisamos passar para o formato largo. O \\$ faz a separação das colunas a partir do momento que nós \"chamamos\" elas. Teste não pareado. Não há depêndencia. Para calcular a normalidade, nós precisamos usar um teste não parametrico. Sendo o p-valor menor do que 0,05, nós rejeitamos H0, até agora o teste t está indicando opções corretas, porém é necessário sabermos se podemos confiar nele. Aplica-se o teste de shapiro wilk para o controle, dado o p-valor, nós podemos aceitar que a distribuição é normal. A hípotese nula é a normalidade e a alternativa é a normal, se ele der maior que 0,05 nós aceitamos a normalidade (aceitando H0). O comprimento é uma varíavel númerica contínua. Se o valor do F é baixo, significa que ele está perto do 0, está situado no meio da curva, nem tão pra direita ou pra esquerda, significa que as variâncias são homogeneas, aceitamos H0 de que ela é homogênea. A partir do teste das variâncias \"var.test\", significa que podemos seguir com o teste t. Se fosse heterogênea, teríamos que justificar que elas são falsas no argumento do t.test (var.equal = FALSE). Típico caso de uma análise parametrica. Podemos também fazer um qqplot para ver se os dados obedecem a linha de tendência, se a maioria dos pontos cair em cima da linha, podemos aceitar também a normalidade dos dados (foi confirmado pelo shapiro test). Podemos usar a função da biblioteca report que pode ser usado como relato em forma de texto da saída do teste t.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmg2 <- mg |> \n  pivot_wider(names_from = trat, \n              values_from = comp)\nt.test(mg2$Mg2, mg2$control)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  mg2$Mg2 and mg2$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(mg2$control)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(mg2$Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(mg2$control)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(mg2$Mg2)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(mg2$control)\nqqline(mg2$control)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n\n```{.r .cell-code}\nvar.test(mg2$control, mg2$Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n```\n\n\n:::\n\n```{.r .cell-code}\nteste1 <- t.test(mg2$Mg2, mg2$control)\n\nlibrary(report)\nreport(teste1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p < .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n```\n\n\n:::\n:::\n\n\n#Dois grupos dependentes Para esse próximo conjunto de teste, temos um teste em formato longo e será um teste pareado, com depêndencia entre os dados. O teste de shapiro wilk mostra a normalidade dos dados, dado que o p-valor é maior do que 0,05 aceitando a H0 e que os dados são normais. Considera-se então que podemos usar o teste t. Através do teste de variância e da análise do box plot, e a partir do p-valor que é menor do que 0,05 rejeitamos H0 e aceitamos que as variâncias são heterogêneas. Se a procentagem do intervalo de confiança não tem o valor 0 no meio, já pode tomar os dados como significativo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nescala <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nescala |> \n  ggplot(aes(assessment, acuracia)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nescala2 <- escala |>\n  select(assessment, rater, acuracia) |>\n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\nt.test(escala2$Aided1, escala2$Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(escala2$Unaided)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(escala2$Aided1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(escala2$Unaided)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(escala2$Aided1)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n```{.r .cell-code}\nvar.test(escala2$Unaided, escala2$Aided1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n```\n\n\n:::\n\n```{.r .cell-code}\n#rever a interpretação\n```\n:::\n\n\n#Teste não paramétrico Utilizado por que o teste de shapiro wilk não deu a normalidade dos dados. Geralmente, os testes paramétricos têm mais poder, mas utilizar o paramétrico ou o não paramétrico está correto os dois tipos de testes desde que você siga as premissas para a utilização de cada teste. Teste t pode ser pareado \"true\" ou não pareado \"false\", dependência ou não dependência. No wilcox não existe não pareado, só o pareado \"true\" ou \"False\", por que usou o pareado para esse conjunto de dados? Por que o mesmo \"fator\" foi avaliado duas vezes por uma mesma pessoa, dando a entender uma relação de dependência entre os dados. O wilcox teste é o equivalente não paramétrico do teste t.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n```\n\n\n:::\n:::\n\n\n# Três ou mais grupos\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nmicelial <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n```\n:::\n\n\nUsou o geom_jitter por que tem menos de 10 repetições e é legal visualizar os dados um a um. A anova vai testar se existe diferença entre as médias, testando a variabilidade dentro do grupo e entre os grupos. O teste F é a razão entre grupos divididos pela variância dentro de cada grupo, o teste F da menor se a variância entre o grupo é menor, se ela for maior o valor de F vai ser muito alto que vai diminuir o valor p e a probabilidade de achar diferença vai ser muito pequena.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicelial |>\n  ggplot(aes(especie, tcm)) +\n  geom_jitter(width = 0.05)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nTrabalhando os dados na ANOVA A função \"anova\" vai gerar o quadro da anova. A variabilidade entre grupos/variabilidade dentro do grupo da o teste F. Baseado no valor de F calculado (Pr (\\>F)) é maior do que 0,05 então aceitamos H0. Quanto maior o valor de F, menor o valor de P. Em relação a normalidade, os resíduos estão ok. O pacote DHARMa vai nos dar uma visão geral sobre a confiabilidade dos dados, do mesmo jeito que os testes de normalidade da variancia e dos dados, vai reunir todos os dados de verificação em um único local que facilitará a visualização.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- lm(tcm ~especie -1, data = micelial)\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nespecie    5 51.677 10.3354   552.2 < 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \nespecieFasi  1.57167    0.05585   28.14  < 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  < 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  < 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991,\tAdjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n ##m1 <- lm(tcm ~especie -1, data = micelial) adiciona o -1 pra retirar o intercept\nhist(m1$residuals)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nshapiro.test(m1$residuals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n```\n\n\n:::\n\n```{.r .cell-code}\nbartlett.test(tcm ~ especie, data = micelial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)\nmedias1 <- emmeans(m1, ~ especie)\nmedias1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals (m1))\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.878).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.880).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n:::\n\n\n#Aula 7 O count vai fazer a contagem do número que se repete do elemento no spray A. Os sprays A,B,D,E,F são os níveis do fator inseticida.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheme_set(theme_bw())\ninseticida <- InsectSprays\nlibrary(tidyverse)\ninseticida |>\n  count(spray)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n```\n\n\n:::\n\n```{.r .cell-code}\nins <- inseticida |>\n  ggplot(aes(spray,count)) +\n  geom_boxplot() \nins\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nshapiro.test(inseticida$count)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  inseticida$count\nW = 0.9216, p-value = 0.0002525\n```\n\n\n:::\n:::\n\n\nPrimeiro trabalha com os resíduos da anova, ajusta o modelo e pega esses resíduos e aplica então os testes. A maioria das pessoas roda a anova, pega os dados de p-valor e roda os testes, sem rodar as premissas de normalidade e homogeineidade. Porém, o certo é testar as premissas. 1- Podemos fazer uma histograma dos resíduos só para ver como está a sua distribuição.Maneira bem visual de verificar a normalidade e distribuição. 2- o teste do shapiro é mais sensível a qualquer desvio, o pvalor sugere que rejeitemos H0. Então, os dados não são normais. 3- A análise que tem mais peso é a heterogeinidade das variâncias, muito mais do que a falta de normalidade. 4- Teste de bartlett testa a homogeineidade das variâncias das amostras, de acordo com o bartlett as variâncias são heterogeneas. 5- Pode recorrer as transformações, log(x), log(x=0.5), raiz quadrado (geralmente é uma boa opção para dados discretos/de contagem). O plot do emmeans da as médias estimadas de cada nível do fator.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- lm(count ~ spray,\n         data = inseticida)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  14.5000     1.1322  12.807  < 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,\tAdjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nspray      5 2668.8  533.77  34.702 < 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)\nm1_medias <- emmeans(m1, ~ spray)\nplot(m1_medias)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(multcomp)\ncld(m1_medias)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\nhist(m1$residuals)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n```{.r .cell-code}\nshapiro.test(m1$residuals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n```\n\n\n:::\n\n```{.r .cell-code}\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n\n```{.r .cell-code}\nbartlett.test(count ~ spray, \n              data = inseticida)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Non-normality of residuals detected (p = 0.022).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n```\n\n\n:::\n:::\n\n\n#Alternativa 1 Agora vamos tentar transformar os dados para torná-los normais. 1- pelo gráfico percebe-se que os dados ficaram um pouco mais normais.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninseticida <- inseticida |>\n  mutate(count2 = sqrt(count)) \n\ninseticida |> \n  ggplot(aes(spray, count2)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n:::\n\n\nAgora percebe-se que conseguiu normalizar os dados, p-valor de shapiro.test maior que 0,05, aceita H0. Levene test nos residuos do dharma, bartlet test e check_heteroscedasticity para verificar a homogeneidade da variância. A ANOVA é um teste mais resistente/robusto a falta de normalidade do que para homostacidade... O modelo com a transformação houve mais discriminação entre as médias, o valor não transformado favoreceu o erro tipo 1. Com a transformação, houve uma maior discriminação/separação de diferença entre as médias.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- lm(count2 ~ spray, \n         data = inseticida)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   3.7607     0.1814  20.733  < 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,\tAdjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nspray      5 88.438 17.6876  44.799 < 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)\nm2_medias <- emmeans(m2, ~ spray)\nplot(m2_medias)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(multcomp)\ncld(m2_medias)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\npairs(m2_medias)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  <.0001\n A - D       1.596 0.257 66   6.223  <.0001\n A - E       1.951 0.257 66   7.606  <.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  <.0001\n B - D       1.712 0.257 66   6.675  <.0001\n B - E       2.067 0.257 66   8.058  <.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  <.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  <.0001\n E - F      -2.209 0.257 66  -8.612  <.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n```\n\n\n:::\n\n```{.r .cell-code}\npwpm(m2_medias)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       A      B      C      D      E      F\nA [3.76] 0.9975 <.0001 <.0001 <.0001 0.9145\nB -0.116 [3.88] <.0001 <.0001 <.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 <.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 <.0001\nE  1.951  2.067 -0.565  0.355 [1.81] <.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n```\n\n\n:::\n\n```{.r .cell-code}\npwpp(m2_medias)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-12-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(m2$residuals)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-12-3.png){width=672}\n:::\n\n```{.r .cell-code}\nshapiro.test(m2$residuals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n```\n\n\n:::\n\n```{.r .cell-code}\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-12-4.png){width=672}\n:::\n\n```{.r .cell-code}\nbartlett.test(count2 ~ spray, \n              data = inseticida)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.681).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.854).\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(m2))\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-12-5.png){width=672}\n:::\n\n```{.r .cell-code}\n#transformação box-cox \nlibrary(MASS)\nb <- boxcox(lm(inseticida$count+0.1 ~1))\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-12-6.png){width=672}\n:::\n\n```{.r .cell-code}\nlambda <- b$x[which.max(b$y)]\nlambda <- 0.5\n#lambda 0.4242424\n\ninseticida$count3 <- (inseticida$count ^ lambda - 1) / lambda \ninseticida$count3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  4.3245553  3.2915026  6.9442719  5.4833148  5.4833148  4.9282032\n [7]  4.3245553  7.5916630  6.2462113  6.9442719  5.4833148  5.2111026\n[13]  4.6332496  6.2462113  7.1651514  4.6332496  6.0000000  5.4833148\n[19]  6.2462113  6.2462113  6.7177979  7.1651514  3.2915026  5.2111026\n[25] -2.0000000  0.0000000  3.2915026  0.8284271  1.4641016  0.0000000\n[31]  0.8284271  0.0000000  1.4641016 -2.0000000  0.0000000  2.0000000\n[37]  1.4641016  2.4721360  4.9282032  2.8989795  2.0000000  1.4641016\n[43]  2.4721360  2.4721360  2.4721360  2.4721360  0.8284271  2.0000000\n[49]  1.4641016  2.4721360  1.4641016  2.4721360  1.4641016  2.8989795\n[55]  0.0000000  0.0000000  1.4641016  0.8284271  2.8989795  2.0000000\n[61]  4.6332496  4.0000000  5.7459667  7.3808315  5.7459667  6.0000000\n[67]  5.2111026  4.3245553  8.1980390  8.1980390  7.7979590  5.2111026\n```\n\n\n:::\n:::\n\n\n#Alternativa 2- utilizar teste paramétrico quando há violação das premissas H0= médias iguais, rejeita hípotese nula por que o p-valor do kruskal teste é menor que 0.05\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(agricolae)\nkruskal.test(count ~ spray, \n             data = inseticida)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n```\n\n\n:::\n\n```{.r .cell-code}\nm3 <- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\nm3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n```\n\n\n:::\n:::\n\n\n#Alternativa 3- modelo 4 -\\> GLMs m4_medias \\<- emmeans(m4, \\~ spray, type = \"response\") m4_medias -\\> demonstra que 95% das vezes a média dos fatores está entre asymp.LCL e asymp.UCL\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm4 <- glm(count ~ spray,\n          family = poisson,\n          data = inseticida)\nsummary(m4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  2.67415    0.07581  35.274  < 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  < 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  < 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(m4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(car)\nAnova(m4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(>Chisq)    \nspray   310.71  5  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(m4))\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm4_medias <- emmeans(m4, ~ spray, \n                     type = \"response\")\nm4_medias\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n spray  rate    SE  df asymp.LCL asymp.UCL\n A     14.50 1.099 Inf     12.50     16.82\n B     15.33 1.130 Inf     13.27     17.72\n C      2.08 0.417 Inf      1.41      3.08\n D      4.92 0.640 Inf      3.81      6.35\n E      3.50 0.540 Inf      2.59      4.74\n F     16.67 1.179 Inf     14.51     19.14\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(multcomp)\ncld(m4_medias)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n#Importação de dados para trabalhar com um experimento fatorial Anova fatorial 2 way\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nli <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ng1 <- li |> \n  ggplot(aes(factor (dose), severity, color = factor(dose))) +\n  geom_jitter(width = 0.1) +\n  facet_wrap(~treat) +\n  theme_bw()\ng1\n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n##Modelo fatorial (two-way anova) A resposta em função de quem? Dos dois fatores. Caso com interação significativa, olhar p-valor, precisa fazer as médias da combinação dos fatores. Tem que fazer uma tabela como essa abaixo e estimar as médias:\n\n```         \n  0,5        2,0\n```\n\nli med Aa med Ab Teb med Ba med Ab\n\nTem que comparar a dose entre os fungicidas, comparar os fungicidas entre eles e os fungicidas influenciados pelas doses. O mesmo fungicida em duas doses e a mesma dose entre os dois fungicidas. Quando a interação da significativa, tem que realizar os desdobramentos dessa interação. Antes de realizar o teste de média, tem que ser testada as premissas de normalidade e de homogeinidade. O DHARMa diz que não teve problema com a análise dos resíduos. Por que fazer a normalidade e a homogeinidade dos resíduos?\n\nComparando os dados na coluna, para comparar na linha é necessário trocar o comando.\n\n```         \n   0,5       2,0\n```\n\nLI 0,29 Aa 0,05 Ab TEB 0,02 Ba 0,02 Aa\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmf <- lm(severity ~ treat*dose,\n         data = li) \nmf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = severity ~ treat * dose, data = li)\n\nCoefficients:\n           (Intercept)       treatTebuconazole                    dose  \n                0.3728                 -0.3515                 -0.1613  \ntreatTebuconazole:dose  \n                0.1608  \n```\n\n\n:::\n\n```{.r .cell-code}\nanova(mf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(>F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(simulateResiduals(mf)) #ok pode seguir \n```\n\n::: {.cell-output-display}\n![](aula6_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#mf_medias <- emmeans(mf, ~ treat | dose)\nmf_medias <- emmeans(mf, ~ dose | treat)\ncld(mf_medias)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}