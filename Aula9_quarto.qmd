---
title: "Aula 9- experimento fatorial e ajuste de modelos"
format: html
editor_options: 
message: false 
warning: false
---

# Importação de dados

Podridão de Fusarium em milho Parcela subdividida. Dentro de cada bloco foi casualizado os híbridos. O método de aplicação foi casualizado dentro dos híbridos

Modelo misto: fator fixo + fator aleatório

Experimento fatorial, DBC com parcela subdividida (4 blocos, aleatorizando a parcela princial dentro de cada bloco, nesse caso foi o híbrido, cada um dentro de cada bloco. O bloco é subdividido e aleatorizado com o método dentro de cada bloco. Sorteia o híbrido e sorteia a posição de cada método). Duas opções: usar lm ou aov, ou usar o modelo misto (quando tem uma mistura de um fator fixo e um fator aleatório do modelo, tem que considerar o efeito aleátorio do híbrido dentro do bloco e do método no híbrido).

```{r}
library(gsheet)
library(tidyverse)

milho <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759")

```

## Visualizar dados

```{r}
milho |> 
  ggplot(aes(method, index))+
  geom_jitter(width = 0.1, color = "black", alpha = 0.2)+
  facet_grid(~hybrid)+
  stat_summary(fun.data = "mean_cl_boot", color = "blue")
#Dependendo do híbrido parece que há efeito do método

milho |> 
  ggplot(aes(method, yield))+
  geom_jitter(width = 0.1, color = "black", alpha = 0.2)+
  facet_grid(~hybrid)+
  stat_summary(fun.data = "mean_cl_boot", color = "red")
```

## Modelo para parcela subdividida - index

Na ANOVA pode ser observado que a interação entre o híbrido e o método é significativo, a partir dai temos que fazer os desdobramentos dessa interação. Pacote para estimar as médias -\> emmeans

```{r}
library(lme4)

milho <- milho |> 
  mutate(block = as.factor(block))

mix <- lmer(index ~ hybrid*method + block + (1|block/hybrid), 
             data = milho)

library(car)
Anova(mix)

#Pelo menos um híbrido é diferente dos demais, assim como existe diferença significativa entre métodos.
#Também existe diferença na interação híbrido com método

library(performance)
check_normality(mix)
check_heteroscedasticity(mix)
#Observou heterogeneicidade das variâncias

library(DHARMa)
plot(simulateResiduals(mix))


#Transformação com raiz quadrada
mix2 <- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), 
             data = milho)
Anova(mix2)
check_normality(mix2)
check_heteroscedasticity(mix2)
#Deu distribuição normal e homocedasticidade
plot(simulateResiduals(mix2))

qqnorm(residuals(mix2))
qqline(residuals(mix2))
hist(residuals(mix2))

library(emmeans)
medias_milho <- emmeans(mix2,
                        ~hybrid|method,
                        type = "response") #Qaundo transforma dados, precisa colocar type = response
medias_milho
medias_milho2 <- emmeans(mix2,
                         ~method|hybrid,
                         type = "response")
medias_milho2

library(multcomp)
library(multcompView)
cld(medias_milho, Letters = LETTERS)
cld(medias_milho2, Letters = letters)


```

## Modelo para parcela subdividida - yield

```{r}
mix3 <- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid), 
             data = milho)

Anova(mix3)

#Pelo menos um híbrido é diferente dos demais, assim como existe diferença significativa entre métodos.
#Também existe diferença na interação híbrido com método

library(performance)
check_normality(mix3)
check_heteroscedasticity(mix3)

library(emmeans)
medias_milho3 <- emmeans(mix3,
                        ~hybrid|method,
                        type = "response") #Qaundo transforma dados, precisa colocar type = response
medias_milho
medias_milho4 <- emmeans(mix3,
                         ~method|hybrid,
                         type = "response")
medias_milho2

library(multcomp)
library(multcompView)
cld(medias_milho3, Letters = LETTERS)
cld(medias_milho4, Letters = letters)
```

# Regressão linear

Experimento feito com a inoculação de patogenos nas sementes de arroz. 3%, 12%, 24% e 48%. A hipotése é que conforme aumenta o inoculo do patogeno, diminui o estande de plantas, feito em locais (anos) diferentes. É uma variável númerica contínua, qual a tendência? o padrão? será que tem efeito positivo ou negativo? Espera-se que o número de plantas vai diminuindo. Quer saber a consistência dos resultados em épocas diferentes. X o tratamento, y o número de plantas Geom_smooth faz a linha da regressão linear, indica uma taxa de redução entre os experimentos. Foi mais inclinada onde teve uma maior variação entre as taxas. Mostra que há efeito da inoculação do fungo bipolaris oryzae em arroz, causando redução do estande de plantas conforme aumenta o inoculo. Será que a taxa de redução é significativa? Será que -0,24 é diferente de 0? Tem que olhar o valor do coeficiente estimado do tratamento. Olhando o p-valor do modelo linear, percebe-se que não há diferença, aceita a hipotese nula e assume que o tratamento não tem efeito. Para o experimento 1. Para o experimento 2, rejeita a H0.

```{r}
estande <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555")
```

```{r}
estande |> 
  ggplot(aes(trat, nplants))+
  geom_jitter(width = 0.1, color = "gray")+
  facet_wrap(~exp)+
  stat_summary(fun.data = "mean_cl_boot", color = "blue")+
  geom_smooth(method = "lm", se = F) #se = F tira a banda de confiança

estande |> 
  ggplot(aes(trat, nplants, color = factor(exp)))+
  geom_jitter(width = 0.1, color = "gray")+
  stat_summary(fun.data = "mean_cl_boot", color = "blue")+
  geom_smooth(method = "lm", se = F)

exp1 <- estande |> 
  filter(exp == 1)

exp1 |> 
  ggplot(aes(trat, nplants))+
  geom_point()+
  ylim(0,100)+
  geom_smooth(se = F)


#Modelo Linear
lm1 <- lm(nplants ~ trat,
          data = exp1)
summary(lm1)
#Taxa de redução é -0.24 (quase 25%) - para cada unidade de x reduz o y em -0.24
#Não rejeita a hipótese nula (a taxa de redução não é diferente de 0)


#Fazendo o mesmo para experimento 2
exp2 <- estande |> 
  filter (exp == 2)

exp2 |> 
  ggplot(aes(trat, nplants))+
  geom_point()+
  ylim(0,100)+
  geom_smooth(method = lm, se = F)

lm2 <- lm(nplants ~ trat,
          data = exp2)
summary(lm2)
#Taxa de redução é -0.70 - para cada unidade de x reduz o y em -0.70
#Rejeita hipótese nula

#Mesmo para o experimento 3
exp3 <- estande |> 
  filter (exp == 3)

exp3 |> 
  ggplot(aes(trat, nplants))+
  geom_point()+
  ylim(0,100)+
  geom_smooth(method = lm, se = F)

lm3 <- lm(nplants ~ trat,
          data = exp3)
summary(lm3)
#Coeficiente de determinação (adjusted R-squared): 59% da variabilidade do Y (número de plantas) é explicado pelo X (inóculo)
#O máximo desse coeficiente é 1

residuals(lm3)
hist(residuals(lm3))
hist(residuals(lm2))

#Se transformar o log dos tratamentos, os dados ficarão mais linearizado (diminui a curva)
exp2 |> 
  ggplot(aes(log(trat), nplants))+
  geom_point()+
  ylim(0,100)+
  geom_smooth(se = F)

#Outra alternativa é realizar o glm (modelo linear generalizado)
glm1 <- glm(nplants ~ trat,
            family = "gaussian",
            data = exp1)
summary(glm1) #A família gaussiana é o mesmo que o método "lm", resulta em taxa de redução -0.24 tbm

glm2 <- glm(nplants ~ trat,
            family = "gaussian",
            data = exp2)
summary(glm2)
AIC(glm2)

glm2b <- glm(nplants ~ trat,
             family = poisson(link = "log"),
             data = exp2)
summary(glm2b)
AIC(glm2b)

glm3 <- glm(nplants ~ trat,
            family = "gaussian",
            data = exp3)
summary(glm3)
AIC(glm3)

glm3b <- glm(nplants ~ trat,
             family = poisson(link = "log"),
             data = exp3)
summary(glm3b)
AIC(glm3b) #melhor qualidade de ajuste, quanto menor é melhor (mais ajustado)
```

#Como fazer a comparação entre diferentes modelos, usando os mesmos dados. Linera. Poisson. Quanto menor o valor de AIC melhor é. O modelo de poisson é melhor para o experimento 3, por que o AIC deu um valor menor, o que significa que o modelo de ajuste é melhor usar o poisson.

```{r}
library(lme4)
glm4 <- glmer(nplants ~ trat + (trat|exp),
            family = "gaussian",
            data = estande)
summary(glm4)
AIC(glm4)

glm4b <- glmer(nplants ~ trat + (trat|exp),   #(trat|exp) é o efeito aleatório
             family = poisson(link = "log"),
             data = estande)
summary(glm4b)
AIC(glm4b)

#Pegando os dados de maneira geral, o gaussiano é melhor (menor AIC)
#Desse modo podemos usar o gaussiano
```

Para prever a produtividade em função da incidência do mofo branco Relação entre variáveis respostas

```{r}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("Icens")

remotes::install_github("emdelponte/r4pde")
library(r4pde)

wm <- WhiteMoldSoybean

wm |> 
  ggplot(aes(inc, yld, group = factor(study)))+
  geom_point()+
  #facet_wrap(~ study)+
  geom_smooth(method = "lm", se = F)+
  theme_minimal()

mofo1 <- lm(yld ~ inc,
            data = wm)
summary(mofo1) #Modelo global
#Intercept é a produtividade com incidência 0
```

```{r}
library(broom)
mofo2 <- wm |> 
  group_by(study) |> 
  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))
mofo2

df<- mofo2 |> 
  filter(term == ".$inc")
mean(df$estimate)

#Histograma da produtividade quando incidência é 0
p1 <- mofo2 |> 
  filter(term == "(Intercept)") |> 
           ggplot(aes(x = estimate))+
           geom_histogram(bins = 8, color = "white", fill = "gray")+
           theme_r4pde()+
           labs(x = "Intercept", y = "frequency")
p2 <- mofo2 |> 
  filter(term == ".$inc") |> 
           ggplot(aes(x = estimate))+
           geom_histogram(bins = 8, color = "white", fill = "gray")+
           theme_r4pde()+
           labs(x = "Slopes", y = "frequency")
library(patchwork)
p1+p2
```

```{r}
library(lme4)
mofo3 <- lmer(yld ~ inc + (inc|study), data = wm, REML = F)
summary(mofo3)
#Esta estimativa é muito mais confiável
# Inc do efeito fico sendo -17 é mais confiável, os outros métodos subestimam os valores
#A incidência está causando uma redução na produtividade de -17kg (à medida que a incidência aumenta, a produtividade diminui em 17kg)

Anova(mofo3)
confint(mofo3, method = "Wald")
```
