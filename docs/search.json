[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Saudações, seja muito bem-vindo!",
    "section": "",
    "text": "Olá, me Chamo Mariana Martins, esse é o site destinado ao meu caderno de aulas da disciplina FIP 606, por favor, sinta-se à vontade!\n\n\n\n\n\n\n\n\n\nSobre mim\nEngenheira Agrônoma pela Universidade Federal do Vale do São Francisco, campus de Ciências Agrárias. Atuei como estagiária voluntária no centro de recuperação de áreas degradadas (CRAD), voluntária no laboratório de fitopatologia e fui bolsista de iniciação científica do Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) de 08/2020 a 12/2022, trabalhando atributos de qualidade do solo, controle biológico e microrganismos promotores de crescimento vegetal, sob orientação do professor Bruno Coutinho Moreira. Atualmente sou aluna do mestrado em Fitopatologia (Capes 7) pela Universidade Federal de Viçosa - Campus Viçosa, e atuo no Laboratório de Manejo Integrado de Doenças (LAMID), sob orientação do professor Franklin Jackson Machado. |\n\n\n\n\n\n\n\n\n\n\nSobre esse site\nA proposta desse website é disponibilizar as aulas que foram ministradas na disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia, da Universidade Federal de Viçosa, pelo professor Emerson Medeiros Del Ponte.\nEspero que aproveite o conteúdo!!\n |"
  },
  {
    "objectID": "Aula9_quarto.html",
    "href": "Aula9_quarto.html",
    "title": "Aula 9- experimento fatorial e ajuste de modelos",
    "section": "",
    "text": "Podridão de Fusarium em milho Parcela subdividida. Dentro de cada bloco foi casualizado os híbridos. O método de aplicação foi casualizado dentro dos híbridos\nModelo misto: fator fixo + fator aleatório\nExperimento fatorial, DBC com parcela subdividida (4 blocos, aleatorizando a parcela princial dentro de cada bloco, nesse caso foi o híbrido, cada um dentro de cada bloco. O bloco é subdividido e aleatorizado com o método dentro de cada bloco. Sorteia o híbrido e sorteia a posição de cada método). Duas opções: usar lm ou aov, ou usar o modelo misto (quando tem uma mistura de um fator fixo e um fator aleatório do modelo, tem que considerar o efeito aleátorio do híbrido dentro do bloco e do método no híbrido).\n\nlibrary(gsheet)\nlibrary(tidyverse)\n\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n\n\n\n\nmilho |&gt; \n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.1, color = \"black\", alpha = 0.2)+\n  facet_grid(~hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")\n\n\n\n\n\n\n\n#Dependendo do híbrido parece que há efeito do método\n\nmilho |&gt; \n  ggplot(aes(method, yield))+\n  geom_jitter(width = 0.1, color = \"black\", alpha = 0.2)+\n  facet_grid(~hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nNa ANOVA pode ser observado que a interação entre o híbrido e o método é significativo, a partir dai temos que fazer os desdobramentos dessa interação. Pacote para estimar as médias -&gt; emmeans\n\nlibrary(lme4)\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n\nmix &lt;- lmer(index ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\n\nlibrary(car)\nAnova(mix)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Pelo menos um híbrido é diferente dos demais, assim como existe diferença significativa entre métodos.\n#Também existe diferença na interação híbrido com método\n\nlibrary(performance)\ncheck_normality(mix)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\ncheck_heteroscedasticity(mix)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n#Observou heterogeneicidade das variâncias\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix))\n\n\n\n\n\n\n\n#Transformação com raiz quadrada\nmix2 &lt;- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0718  3   0.994997   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\n#Deu distribuição normal e homocedasticidade\nplot(simulateResiduals(mix2))\n\n\n\n\n\n\n\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n\n\n\n\n\n\n\nhist(residuals(mix2))\n\n\n\n\n\n\n\nlibrary(emmeans)\nmedias_milho &lt;- emmeans(mix2,\n                        ~hybrid|method,\n                        type = \"response\") #Qaundo transforma dados, precisa colocar type = response\nmedias_milho\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nmedias_milho2 &lt;- emmeans(mix2,\n                         ~method|hybrid,\n                         type = \"response\")\nmedias_milho2\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_milho, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nmix3 &lt;- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\n\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Pelo menos um híbrido é diferente dos demais, assim como existe diferença significativa entre métodos.\n#Também existe diferença na interação híbrido com método\n\nlibrary(performance)\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\nlibrary(emmeans)\nmedias_milho3 &lt;- emmeans(mix3,\n                        ~hybrid|method,\n                        type = \"response\") #Qaundo transforma dados, precisa colocar type = response\nmedias_milho\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nmedias_milho4 &lt;- emmeans(mix3,\n                         ~method|hybrid,\n                         type = \"response\")\nmedias_milho2\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_milho3, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  A    \n 30S31H       8081 743 26.1     6626     9681  AB   \n 30F53 YH     9314 798 26.1     7746    11027  ABC  \n 30F53 HX    11130 872 26.1     9410    12995   BC  \n 30K64       11666 893 26.1     9903    13574    C  \n BG7049H     11914 903 26.1    10131    13841    C  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  A    \n 30F53 YH     9079 788 26.1     7532    10770  A    \n 30S31H       9135 790 26.1     7583    10832  A    \n 30F53 HX     9932 824 26.1     8311    11698  AB   \n 30K64       10331 840 26.1     8676    12131  AB   \n BG7049H     12822 936 26.1    10970    14818   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho4, Letters = letters)\n\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  a    \n pin       11130 872 26.1     9410    12995   b   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  a    \n pin        9314 798 26.1     7746    11027  a    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  a    \n pin       11666 893 26.1     9903    13574   b   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  a    \n silk       9135 790 26.1     7583    10832   b   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  a    \n silk       8257 751 26.1     6785     9873  a    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  a    \n silk      12822 936 26.1    10970    14818  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9_quarto.html#visualizar-dados",
    "href": "Aula9_quarto.html#visualizar-dados",
    "title": "Aula 9- experimento fatorial e ajuste de modelos",
    "section": "",
    "text": "milho |&gt; \n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.1, color = \"black\", alpha = 0.2)+\n  facet_grid(~hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")\n\n\n\n\n\n\n\n#Dependendo do híbrido parece que há efeito do método\n\nmilho |&gt; \n  ggplot(aes(method, yield))+\n  geom_jitter(width = 0.1, color = \"black\", alpha = 0.2)+\n  facet_grid(~hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"red\")"
  },
  {
    "objectID": "Aula9_quarto.html#modelo-para-parcela-subdividida---index",
    "href": "Aula9_quarto.html#modelo-para-parcela-subdividida---index",
    "title": "Aula 9- experimento fatorial e ajuste de modelos",
    "section": "",
    "text": "Na ANOVA pode ser observado que a interação entre o híbrido e o método é significativo, a partir dai temos que fazer os desdobramentos dessa interação. Pacote para estimar as médias -&gt; emmeans\n\nlibrary(lme4)\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n\nmix &lt;- lmer(index ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\n\nlibrary(car)\nAnova(mix)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Pelo menos um híbrido é diferente dos demais, assim como existe diferença significativa entre métodos.\n#Também existe diferença na interação híbrido com método\n\nlibrary(performance)\ncheck_normality(mix)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\ncheck_heteroscedasticity(mix)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n#Observou heterogeneicidade das variâncias\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix))\n\n\n\n\n\n\n\n#Transformação com raiz quadrada\nmix2 &lt;- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0718  3   0.994997   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\n#Deu distribuição normal e homocedasticidade\nplot(simulateResiduals(mix2))\n\n\n\n\n\n\n\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n\n\n\n\n\n\n\nhist(residuals(mix2))\n\n\n\n\n\n\n\nlibrary(emmeans)\nmedias_milho &lt;- emmeans(mix2,\n                        ~hybrid|method,\n                        type = \"response\") #Qaundo transforma dados, precisa colocar type = response\nmedias_milho\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nmedias_milho2 &lt;- emmeans(mix2,\n                         ~method|hybrid,\n                         type = \"response\")\nmedias_milho2\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_milho, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9_quarto.html#modelo-para-parcela-subdividida---yield",
    "href": "Aula9_quarto.html#modelo-para-parcela-subdividida---yield",
    "title": "Aula 9- experimento fatorial e ajuste de modelos",
    "section": "",
    "text": "mix3 &lt;- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\n\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Pelo menos um híbrido é diferente dos demais, assim como existe diferença significativa entre métodos.\n#Também existe diferença na interação híbrido com método\n\nlibrary(performance)\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\nlibrary(emmeans)\nmedias_milho3 &lt;- emmeans(mix3,\n                        ~hybrid|method,\n                        type = \"response\") #Qaundo transforma dados, precisa colocar type = response\nmedias_milho\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nmedias_milho4 &lt;- emmeans(mix3,\n                         ~method|hybrid,\n                         type = \"response\")\nmedias_milho2\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_milho3, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  A    \n 30S31H       8081 743 26.1     6626     9681  AB   \n 30F53 YH     9314 798 26.1     7746    11027  ABC  \n 30F53 HX    11130 872 26.1     9410    12995   BC  \n 30K64       11666 893 26.1     9903    13574    C  \n BG7049H     11914 903 26.1    10131    13841    C  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  A    \n 30F53 YH     9079 788 26.1     7532    10770  A    \n 30S31H       9135 790 26.1     7583    10832  A    \n 30F53 HX     9932 824 26.1     8311    11698  AB   \n 30K64       10331 840 26.1     8676    12131  AB   \n BG7049H     12822 936 26.1    10970    14818   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho4, Letters = letters)\n\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  a    \n pin       11130 872 26.1     9410    12995   b   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  a    \n pin        9314 798 26.1     7746    11027  a    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  a    \n pin       11666 893 26.1     9903    13574   b   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  a    \n silk       9135 790 26.1     7583    10832   b   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  a    \n silk       8257 751 26.1     6785     9873  a    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  a    \n silk      12822 936 26.1    10970    14818  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "aula6.html",
    "href": "aula6.html",
    "title": "Aula 6 e 7- Estatística inferencial: ANOVA e teste de médias",
    "section": "",
    "text": "#Hoje iremos trabalhar com a estatística inferencial $ usado para puxar o dado de uma coluna dentro daquele conjunto de dados; ~ usar um fator em função do outro.\n\nlibrary(gsheet)\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\n#Visualização dos dados Para esse conjunto de dados, nós temos um fator e dois níveis do fator (com e sem Mg). Efeito do magnésio reduzindo o tamanho da lesão, a aplicação de magnésio está induzindo uma reação de indução de resistência. O tamanho da lesão se encontra maior no tratamento controle. Para publicar esse trabalho, precisa testar uma hípotese “com a suplementação de magnésio nós temos uma redução do tamanho da doença” (hípotes experimental), e a hípotes nula nos diz que as médias não diferem (hípotese estatística). No gráfico, vemos um box bem simétrico e uma boa diferença entre as medianas, demonstrando que há possibilidade de existir a diferença.Já da uma indicativa de normalidade por causa da simetria do box, por isso é indicado para muitos tratamentos pela facilidade de visualização.\nPara verificar a diferença ou não, usaremos o teste t (teste mais simples, geralmente utilizado com dois grupos, se estiver a mais temos que fazer uma comparação par a par) uma vez que temos poucos tratamentos, assumindo que existe normalidade dos dados e homogeinidade entre as variâncias. 10 plantas que recebem um tratamento e 10 plantas que recebem outro, o que as torna variáveis independentes.\n\nlibrary(tidyverse)\nmg |&gt; \n  ggplot(aes(trat,comp)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n#Realizar a estatística Para usar o teste t nós precisamos dos vetores separados. Uma vez que o conjunto está no formato longo, precisamos passar para o formato largo. O $ faz a separação das colunas a partir do momento que nós “chamamos” elas. Teste não pareado. Não há depêndencia. Para calcular a normalidade, nós precisamos usar um teste não parametrico. Sendo o p-valor menor do que 0,05, nós rejeitamos H0, até agora o teste t está indicando opções corretas, porém é necessário sabermos se podemos confiar nele. Aplica-se o teste de shapiro wilk para o controle, dado o p-valor, nós podemos aceitar que a distribuição é normal. A hípotese nula é a normalidade e a alternativa é a normal, se ele der maior que 0,05 nós aceitamos a normalidade (aceitando H0). O comprimento é uma varíavel númerica contínua. Se o valor do F é baixo, significa que ele está perto do 0, está situado no meio da curva, nem tão pra direita ou pra esquerda, significa que as variâncias são homogeneas, aceitamos H0 de que ela é homogênea. A partir do teste das variâncias “var.test”, significa que podemos seguir com o teste t. Se fosse heterogênea, teríamos que justificar que elas são falsas no argumento do t.test (var.equal = FALSE). Típico caso de uma análise parametrica. Podemos também fazer um qqplot para ver se os dados obedecem a linha de tendência, se a maioria dos pontos cair em cima da linha, podemos aceitar também a normalidade dos dados (foi confirmado pelo shapiro test). Podemos usar a função da biblioteca report que pode ser usado como relato em forma de texto da saída do teste t.\n\nmg2 &lt;- mg |&gt; \n  pivot_wider(names_from = trat, \n              values_from = comp)\nt.test(mg2$Mg2, mg2$control)\n\n\n    Welch Two Sample t-test\n\ndata:  mg2$Mg2 and mg2$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\nhist(mg2$control)\n\n\n\n\n\n\n\nhist(mg2$Mg2)\n\n\n\n\n\n\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\n\n\n\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\nteste1 &lt;- t.test(mg2$Mg2, mg2$control)\n\nlibrary(report)\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n\n\n#Dois grupos dependentes Para esse próximo conjunto de teste, temos um teste em formato longo e será um teste pareado, com depêndencia entre os dados. O teste de shapiro wilk mostra a normalidade dos dados, dado que o p-valor é maior do que 0,05 aceitando a H0 e que os dados são normais. Considera-se então que podemos usar o teste t. Através do teste de variância e da análise do box plot, e a partir do p-valor que é menor do que 0,05 rejeitamos H0 e aceitamos que as variâncias são heterogêneas. Se a procentagem do intervalo de confiança não tem o valor 0 no meio, já pode tomar os dados como significativo.\n\nlibrary(gsheet)\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nescala2 &lt;- escala |&gt;\n  select(assessment, rater, acuracia) |&gt;\n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\nt.test(escala2$Aided1, escala2$Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\nhist(escala2$Unaided)\n\n\n\n\n\n\n\nhist(escala2$Aided1)\n\n\n\n\n\n\n\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n#rever a interpretação\n\n#Teste não paramétrico Utilizado por que o teste de shapiro wilk não deu a normalidade dos dados. Geralmente, os testes paramétricos têm mais poder, mas utilizar o paramétrico ou o não paramétrico está correto os dois tipos de testes desde que você siga as premissas para a utilização de cada teste. Teste t pode ser pareado “true” ou não pareado “false”, dependência ou não dependência. No wilcox não existe não pareado, só o pareado “true” ou “False”, por que usou o pareado para esse conjunto de dados? Por que o mesmo “fator” foi avaliado duas vezes por uma mesma pessoa, dando a entender uma relação de dependência entre os dados. O wilcox teste é o equivalente não paramétrico do teste t.\n\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nTrês ou mais grupos\n\nlibrary(gsheet)\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\nUsou o geom_jitter por que tem menos de 10 repetições e é legal visualizar os dados um a um. A anova vai testar se existe diferença entre as médias, testando a variabilidade dentro do grupo e entre os grupos. O teste F é a razão entre grupos divididos pela variância dentro de cada grupo, o teste F da menor se a variância entre o grupo é menor, se ela for maior o valor de F vai ser muito alto que vai diminuir o valor p e a probabilidade de achar diferença vai ser muito pequena.\n\nmicelial |&gt;\n  ggplot(aes(especie, tcm)) +\n  geom_jitter(width = 0.05)\n\n\n\n\n\n\n\n\nTrabalhando os dados na ANOVA A função “anova” vai gerar o quadro da anova. A variabilidade entre grupos/variabilidade dentro do grupo da o teste F. Baseado no valor de F calculado (Pr (&gt;F)) é maior do que 0,05 então aceitamos H0. Quanto maior o valor de F, menor o valor de P. Em relação a normalidade, os resíduos estão ok. O pacote DHARMa vai nos dar uma visão geral sobre a confiabilidade dos dados, do mesmo jeito que os testes de normalidade da variancia e dos dados, vai reunir todos os dados de verificação em um único local que facilitará a visualização.\n\nm1 &lt;- lm(tcm ~especie -1, data = micelial)\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\n ##m1 &lt;- lm(tcm ~especie -1, data = micelial) adiciona o -1 pra retirar o intercept\nhist(m1$residuals)\n\n\n\n\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\nlibrary(emmeans)\nmedias1 &lt;- emmeans(m1, ~ especie)\nmedias1\n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nlibrary(DHARMa)\nplot(simulateResiduals (m1))\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)\n\n\n\n\n\n\n\n\n#Aula 7 O count vai fazer a contagem do número que se repete do elemento no spray A. Os sprays A,B,D,E,F são os níveis do fator inseticida.\n\ntheme_set(theme_bw())\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\nins &lt;- inseticida |&gt;\n  ggplot(aes(spray,count)) +\n  geom_boxplot() \nins\n\n\n\n\n\n\n\nshapiro.test(inseticida$count)\n\n\n    Shapiro-Wilk normality test\n\ndata:  inseticida$count\nW = 0.9216, p-value = 0.0002525\n\n\nPrimeiro trabalha com os resíduos da anova, ajusta o modelo e pega esses resíduos e aplica então os testes. A maioria das pessoas roda a anova, pega os dados de p-valor e roda os testes, sem rodar as premissas de normalidade e homogeineidade. Porém, o certo é testar as premissas. 1- Podemos fazer uma histograma dos resíduos só para ver como está a sua distribuição.Maneira bem visual de verificar a normalidade e distribuição. 2- o teste do shapiro é mais sensível a qualquer desvio, o pvalor sugere que rejeitemos H0. Então, os dados não são normais. 3- A análise que tem mais peso é a heterogeinidade das variâncias, muito mais do que a falta de normalidade. 4- Teste de bartlett testa a homogeineidade das variâncias das amostras, de acordo com o bartlett as variâncias são heterogeneas. 5- Pode recorrer as transformações, log(x), log(x=0.5), raiz quadrado (geralmente é uma boa opção para dados discretos/de contagem). O plot do emmeans da as médias estimadas de cada nível do fator.\n\nm1 &lt;- lm(count ~ spray,\n         data = inseticida)\nsummary(m1)\n\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nm1_medias &lt;- emmeans(m1, ~ spray)\nplot(m1_medias)\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(m1_medias)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nhist(m1$residuals)\n\n\n\n\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\n\n\n\n\n\n\nbartlett.test(count ~ spray, \n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\n#Alternativa 1 Agora vamos tentar transformar os dados para torná-los normais. 1- pelo gráfico percebe-se que os dados ficaram um pouco mais normais.\n\ninseticida &lt;- inseticida |&gt;\n  mutate(count2 = sqrt(count)) \n\ninseticida |&gt; \n  ggplot(aes(spray, count2)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n\nAgora percebe-se que conseguiu normalizar os dados, p-valor de shapiro.test maior que 0,05, aceita H0. Levene test nos residuos do dharma, bartlet test e check_heteroscedasticity para verificar a homogeneidade da variância. A ANOVA é um teste mais resistente/robusto a falta de normalidade do que para homostacidade… O modelo com a transformação houve mais discriminação entre as médias, o valor não transformado favoreceu o erro tipo 1. Com a transformação, houve uma maior discriminação/separação de diferença entre as médias.\n\nm2 &lt;- lm(count2 ~ spray, \n         data = inseticida)\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nm2_medias &lt;- emmeans(m2, ~ spray)\nplot(m2_medias)\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\n\n\n\n\nhist(m2$residuals)\n\n\n\n\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\n\n\n\n\nbartlett.test(count2 ~ spray, \n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2))\n\n\n\n\n\n\n\n#transformação box-cox \nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count+0.1 ~1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda &lt;- 0.5\n#lambda 0.4242424\n\ninseticida$count3 &lt;- (inseticida$count ^ lambda - 1) / lambda \ninseticida$count3\n\n [1]  4.3245553  3.2915026  6.9442719  5.4833148  5.4833148  4.9282032\n [7]  4.3245553  7.5916630  6.2462113  6.9442719  5.4833148  5.2111026\n[13]  4.6332496  6.2462113  7.1651514  4.6332496  6.0000000  5.4833148\n[19]  6.2462113  6.2462113  6.7177979  7.1651514  3.2915026  5.2111026\n[25] -2.0000000  0.0000000  3.2915026  0.8284271  1.4641016  0.0000000\n[31]  0.8284271  0.0000000  1.4641016 -2.0000000  0.0000000  2.0000000\n[37]  1.4641016  2.4721360  4.9282032  2.8989795  2.0000000  1.4641016\n[43]  2.4721360  2.4721360  2.4721360  2.4721360  0.8284271  2.0000000\n[49]  1.4641016  2.4721360  1.4641016  2.4721360  1.4641016  2.8989795\n[55]  0.0000000  0.0000000  1.4641016  0.8284271  2.8989795  2.0000000\n[61]  4.6332496  4.0000000  5.7459667  7.3808315  5.7459667  6.0000000\n[67]  5.2111026  4.3245553  8.1980390  8.1980390  7.7979590  5.2111026\n\n\n#Alternativa 2- utilizar teste paramétrico quando há violação das premissas H0= médias iguais, rejeita hípotese nula por que o p-valor do kruskal teste é menor que 0.05\n\nlibrary(agricolae)\nkruskal.test(count ~ spray, \n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nm3 &lt;- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\n#Alternativa 3- modelo 4 -&gt; GLMs m4_medias &lt;- emmeans(m4, ~ spray, type = “response”) m4_medias -&gt; demonstra que 95% das vezes a média dos fatores está entre asymp.LCL e asymp.UCL\n\nm4 &lt;- glm(count ~ spray,\n          family = poisson,\n          data = inseticida)\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\nlibrary(car)\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(DHARMa)\nplot(simulateResiduals(m4))\n\n\n\n\n\n\n\nm4_medias &lt;- emmeans(m4, ~ spray, \n                     type = \"response\")\nm4_medias\n\n spray  rate    SE  df asymp.LCL asymp.UCL\n A     14.50 1.099 Inf     12.50     16.82\n B     15.33 1.130 Inf     13.27     17.72\n C      2.08 0.417 Inf      1.41      3.08\n D      4.92 0.640 Inf      3.81      6.35\n E      3.50 0.540 Inf      2.59      4.74\n F     16.67 1.179 Inf     14.51     19.14\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\nlibrary(multcomp)\ncld(m4_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n#Importação de dados para trabalhar com um experimento fatorial Anova fatorial 2 way\n\nlibrary(gsheet)\nli &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\n\nlibrary(tidyverse)\ng1 &lt;- li |&gt; \n  ggplot(aes(factor (dose), severity, color = factor(dose))) +\n  geom_jitter(width = 0.1) +\n  facet_wrap(~treat) +\n  theme_bw()\ng1\n\n\n\n\n\n\n\n\n##Modelo fatorial (two-way anova) A resposta em função de quem? Dos dois fatores. Caso com interação significativa, olhar p-valor, precisa fazer as médias da combinação dos fatores. Tem que fazer uma tabela como essa abaixo e estimar as médias:\n  0,5        2,0\nli med Aa med Ab Teb med Ba med Ab\nTem que comparar a dose entre os fungicidas, comparar os fungicidas entre eles e os fungicidas influenciados pelas doses. O mesmo fungicida em duas doses e a mesma dose entre os dois fungicidas. Quando a interação da significativa, tem que realizar os desdobramentos dessa interação. Antes de realizar o teste de média, tem que ser testada as premissas de normalidade e de homogeinidade. O DHARMa diz que não teve problema com a análise dos resíduos. Por que fazer a normalidade e a homogeinidade dos resíduos?\nComparando os dados na coluna, para comparar na linha é necessário trocar o comando.\n   0,5       2,0\nLI 0,29 Aa 0,05 Ab TEB 0,02 Ba 0,02 Aa\n\nmf &lt;- lm(severity ~ treat*dose,\n         data = li) \nmf\n\n\nCall:\nlm(formula = severity ~ treat * dose, data = li)\n\nCoefficients:\n           (Intercept)       treatTebuconazole                    dose  \n                0.3728                 -0.3515                 -0.1613  \ntreatTebuconazole:dose  \n                0.1608  \n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(mf)) #ok pode seguir \n\n\n\n\n\n\n\n#mf_medias &lt;- emmeans(mf, ~ treat | dose)\nmf_medias &lt;- emmeans(mf, ~ dose | treat)\ncld(mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "aula3.html",
    "href": "aula3.html",
    "title": "Aula3 - aprendendo a visualizar os dados",
    "section": "",
    "text": "Importa os dados\no conjuto de dados está em uma página da web\n\nlibrary(tidyverse)\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…\n\nlibrary (ggthemes)\ncr |&gt; \n  ggplot (aes (x = sev2, fill = region)) + \n  geom_histogram( color = \"white\") + \n  facet_grid(region~cultivar) + \n  scale_fill_colorblind () +\n  theme_minimal(base_size = 12)+\n  theme (legend.position = \"bottom\") +\n  labs (y= \"Frequency\", \n        x= \"Severity(%)\", fill = \"Region\")\n\n\n\n\n\n\n\nggsave(\"crl.png\", bg = \"white\")\n\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\ncr |&gt; \n  group_by (region) |&gt; \n  summarize (sev_med = median(sev2),\n             sev_mean = mean (sev2),\n             sev_sd = sd (sev2))\n\n# A tibble: 2 × 4\n  region sev_med sev_mean sev_sd\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 Oromia    6.23     8.06   6.82\n2 SNNPR     4.88     9.81  10.5 \n\ncr |&gt; \n  ggplot (aes (inc, sev2)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nVisualização\nvamos utilizar a bibilbioteca ggplot para visualizar os dados\n#cria subconjuntos uTILIZA AS FUNÇÕES “SELECT” E “FILTER” DO PACOTE dplyr para selecionar colunas e linhas, respectivamente.\n\n#filtra oromia \n\ncr_oromia &lt;- cr|&gt;\n  select (farm, region, cultivar, sev2) |&gt;\n  filter(region == \"Oromia\")\ncr_oromia\n\n# A tibble: 165 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1   286 Oromia Mixture   7.63\n 2   287 Oromia Mixture   9.39\n 3   288 Oromia Mixture   1.30\n 4   289 Oromia Mixture   9.79\n 5   290 Oromia Local    18.5 \n 6   291 Oromia Mixture  13.2 \n 7   292 Oromia Mixture   5.60\n 8   293 Oromia Mixture   1.06\n 9   294 Oromia Local    17.6 \n10   295 Oromia Mixture  15.4 \n# ℹ 155 more rows\n\n#filtra SNNPR\ncr_pr &lt;- cr |&gt; \n  select (farm, region, cultivar, sev2) |&gt;\n  filter (region == \"SNNPR\")\ncr_pr\n\n# A tibble: 240 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 230 more rows\n\n\n##Visuzaliza os subconjuntos\nGráfico ggplot para cada subconjunto\n\np1 &lt;- cr_oromia |&gt; \n  ggplot (aes(cultivar, sev2, \n              fill = cultivar))+\n  geom_boxplot()+\n  scale_fill_few () +\n  labs (y = \"Severity (%)\",\n      x= \"\")+\n  coord_flip()\n\np2 &lt;- cr_pr |&gt; \n  ggplot (aes(cultivar, sev2,\n              fill = cultivar)) +\n  geom_boxplot() +\n  scale_fill_few () +\n  labs (y= \"Severity (%)\",\n        x= \"\")+\n  coord_flip()\np1\n\n\n\n\n\n\n\np2\n\n\n\n\n\n\n\nlibrary(patchwork)\n\n(p1 / p2) + \nplot_layout(guides = \"collect\",\n            axes = \"collect\") +\n  plot_annotation(title = \"Coffe rust in Ethiopia\", \n                  caption = \"source: Del Ponte (2022)\")\n\n\n\n\n\n\n\nggsave(\"patchl.png\", bg = \"white\",\n       width = 6,\n       height = 4)\n\np3 &lt;- cr_oromia |&gt; \n  ggplot (aes(x = sev2))+\n  geom_histogram()\n\np1 + inset_element(p3, left = 0.6, bottom = 0.6, right = 1, top = 1)\n\n\n\n\n\n\n\n#se colocar a o sinal de + e a barra |, também vai. Se colocar a barra / coloca um embaixo do outro\n#usa o coord_flip para girar as coordenadas do gráfico"
  },
  {
    "objectID": "aula1_quarto.html",
    "href": "aula1_quarto.html",
    "title": "Aula 1 - introdução ao R",
    "section": "",
    "text": "#Aprendendo a atribuir valores\n\nA &lt;- 1\nB &lt;- 2\nC &lt;- 3\n\nvalores adiconados aqui, irão aparecer como objetos com dados #uso de dois ** para deixar em negrito exemplo #uso de um * deixa ele em itálico exemplo\n#Para criar um data.frame\nIMPORTANTE Tem que ser o mesmo número de linhas e vetores para a criação do dataframe que funciona como uma espécie de tabela.\n\ndf &lt;- data.frame(A, B)\n\n#Como pedir ajuda\nAparece a resposta do que a função faz na aba de ajuda “help” Além da opção apresentada no chunck pode pedir ajuda da seguinte forma: ?função.\n\nhelp(data.frame)\n\n#Também podemos fazer operações Pode fazer operações com os número e também com os vetores com valores atribuidos. O R funciona basicamente como uma calculadora inteligente, portanto, pode ser feita operações matemáticas básicas e complexas.\n\n1 + 1\n\n[1] 2\n\n2/3\n\n[1] 0.6666667\n\n3*4\n\n[1] 12\n\nA + B\n\n[1] 3\n\nC * A\n\n[1] 3\n\nB / C\n\n[1] 0.6666667\n\n\n#Usado para confirmar a informação colocada\nA função ‘echo:false’ desativa o código de impressão (somente a resposta aparece no console).\n\n\n[1] 4"
  },
  {
    "objectID": "aula1_quarto.html#running-code",
    "href": "aula1_quarto.html#running-code",
    "title": "Aula 1 - introdução ao R",
    "section": "",
    "text": "#Aprendendo a atribuir valores\n\nA &lt;- 1\nB &lt;- 2\nC &lt;- 3\n\nvalores adiconados aqui, irão aparecer como objetos com dados #uso de dois ** para deixar em negrito exemplo #uso de um * deixa ele em itálico exemplo\n#Para criar um data.frame\nIMPORTANTE Tem que ser o mesmo número de linhas e vetores para a criação do dataframe que funciona como uma espécie de tabela.\n\ndf &lt;- data.frame(A, B)\n\n#Como pedir ajuda\nAparece a resposta do que a função faz na aba de ajuda “help” Além da opção apresentada no chunck pode pedir ajuda da seguinte forma: ?função.\n\nhelp(data.frame)\n\n#Também podemos fazer operações Pode fazer operações com os número e também com os vetores com valores atribuidos. O R funciona basicamente como uma calculadora inteligente, portanto, pode ser feita operações matemáticas básicas e complexas.\n\n1 + 1\n\n[1] 2\n\n2/3\n\n[1] 0.6666667\n\n3*4\n\n[1] 12\n\nA + B\n\n[1] 3\n\nC * A\n\n[1] 3\n\nB / C\n\n[1] 0.6666667\n\n\n#Usado para confirmar a informação colocada\nA função ‘echo:false’ desativa o código de impressão (somente a resposta aparece no console).\n\n\n[1] 4"
  },
  {
    "objectID": "aula10.html",
    "href": "aula10.html",
    "title": "Análise de correlação",
    "section": "",
    "text": "#install.packages(\"AgroR\")\n\nA correlação é uma relação entre duas ou mais variáveis. Existe uma direção dessa associação, que pode ser forte ou fraca. Ela pode ser linear e positiva. A força da associação está relacionada com a dispersão dos dados, quanto mais disperso os dados mais fraca é a asociação. Então, um dos coeficientes que pode estimar isso é o coeficiente de correlação de Pearson. Quanto mais disperso, mais próximo de zero fica o coeficiente. Ela pode ser negativa quando uma varíaveld diminui em função da outra (ex: produtividade x doença), existindo uma relação de causa/efeito. É usada quando você obtém respostas diferentes e que analisar se existe uma correlação entre as variaveis respostas. Pode ser feita regressão quando o objetivo é predizer y em função de x. Pode chegar em um coeficiente de correlação através de uma análise de regressão, o quanto que a variação de y é explicada pelo x.\nR2 = o quanto da variação de y é explicada pelo x R= a força de associação\n\nlibrary(tidyverse)\nlibrary(gsheet)\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\nimgs |&gt; \n  pivot_longer(3:5, names_to = \"method\", \n               values_to = \"value\") |&gt; \n  ggplot(aes(method, value)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nimgs1 &lt;- imgs |&gt; \n  ggplot(aes(Assess, LeafDoctor)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nimgs1\n\n\n\n\n\n\n\nimgs2 &lt;- imgs |&gt;\n  ggplot(aes(Assess, ImageJ)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") \nimgs2\n\n\n\n\n\n\n\nlibrary(patchwork)\nimgs1 + imgs2\n\n\n\n\n\n\n\n\nEle faz uma matriz de correlação Cor entrega o coeficiente de correlação de pearson. O cor test da uma estatística mais completa. 0,96 é bem próximo de um, então indica uma correlação forte. Quanto maior a correlação menor o p-valor, se os dados forem mais dispersos o p-valor vai ser maior e não vai ser significativo. O corgraph é um pacote que indica a correlação entre as respostas da análise. Os valores dentro da matriz irão indicar o coeficiente de correlação entre as varíaveis observadas.\n\nimgs3 &lt;- imgs |&gt; \n  select(3:5)\n  \nlibrary(AgroR)\ncorgraph(imgs3)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\n\n\n\ncor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\ncor(imgs$Assess, imgs$LeafDoctor)\n\n[1] 0.9666367\n\nlibrary(corrplot)\ncor_imgs2 &lt;- cor(imgs3) \ncorrplot(cor_imgs2, method = \"number\", type = \"lower\", diag = FALSE) \n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\ncampo2 &lt;- campo |&gt; \n  select (DFC, FER, PROD)\nlibrary(AgroR)\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\n\n\n\ncampo |&gt;\n  ggplot(aes(DFC, PROD)) +\n  geom_point()\n\n\n\n\n\n\n\n\nO modelo quadratico é um experimento melhor do que o de primeira ordem, explica melhor o que vemos no gráfico anterior e a variação dos desvios. Pode ser utilizado essa variação, predizer o numero de plantas afetadas. y = (66,3 - 1,77trat) + (0,02trat^2) : equação do modelo\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nestande |&gt;\n  ggplot(aes(trat, nplants, color = factor (exp))) +\n  geom_boxplot() +\n  facet_wrap(~ exp) +\n  theme_bw() +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5,\n               color = \"black\")\n\n\n\n\n\n\n\nestande |&gt;\n  ggplot(aes(trat, nplants, color = factor (exp))) +\n  geom_jitter(width = 0.1, alpha = 0.2) +\n  facet_wrap(~exp) +\n  theme_bw() +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5,\n               color = \"black\") +\n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\nexp2 &lt;- estande |&gt;\n  filter (exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants)) +\n  geom_point() +\n  ylim(0,100) +\n  geom_smooth(method = \"lm\", se = F, formula = y ~poly(x,2), color = \"black\") +\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n\n\n\n\n\n\n\n#MODELO LINEAR\n\nexp2$trat2 &lt;- exp2$trat^2\n\n#primeira ordem\nlm2 &lt;- lm(nplants ~ trat, \n          data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nhist(residuals(lm2))\n\n\n\n\n\n\n\n#segunda ordem\n\nlm3 &lt;- lm(nplants ~ trat + trat2, \n          data = exp2)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\nhist(residuals(lm3))\n\n\n\n\n\n\n\nAIC(lm2)\n\n[1] 194.9597\n\nAIC(lm3)\n\n[1] 193.1284\n\nlibrary(AgroR)\nwith(exp2, polynomial(trat, nplants, grau = 3))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n\n\n[[1]]\n\n\n\n\n\n\n\n\n#library(agro3)\n#data(\"phao\")\n#with(phao, polynomial(dose, comp, grau = 2))\n\n\nlibrary(gsheet)\npyra &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\") \n\nlibrary(tidyverse)\n\npyra |&gt;\n  group_by(code, dose) |&gt;\n  summarise(mean_germination = mean(germination)) |&gt; \n  ggplot(aes(dose, mean_germination)) +\n  geom_point() +\n  facet_wrap(~code) +\n  labs(y = \"Germination\",\n         x = \"Dose\")\n\n\n\n\n\n\n\npyra2 &lt;- pyra |&gt;\n  group_by(code, dose) |&gt;\n  summarise(mean_germination = mean(germination)) \n \nlibrary(drc)\n\nisolado186 &lt;- pyra2 |&gt;\n  filter(code == \"186\")\n\ndrc1 &lt;- drm(mean_germination ~ dose, data = isolado186,\n            fct = LL.3())\nAIC(drc1)\n\n[1] 21.11219\n\nplot(drc1)\n\n\n\n\n\n\n\nED(drc1, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.579757   0.013332 0.537328 0.622187\n\nsummary(drc1)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  4.997636   0.542650  9.2097  0.002708 ** \nd:(Intercept) 48.750109   0.721642 67.5545 7.148e-06 ***\ne:(Intercept)  0.579757   0.013332 43.4853 2.677e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.020525 (3 degrees of freedom)\n\nlibrary(ec50estimator)\n\n\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose, \n                         data = pyra2, \n                         isolate_col = \"code\",\n                         interval = \"delta\", \n                         fct = drc::LL.3())\n\ndf_ec50 |&gt;\n  ggplot(aes(reorder(ID, Estimate), Estimate)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = Lower, ymax= Upper), width = 0.1) +\n  coord_flip()\n\n\n\n\n\n\n\nlibrary(ec50estimator) #Permite estimar o ec50 de todos os isolados ao mesmo tempo\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose,\n                         data = pyra2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\ndf_ec50\n\n      ID strata   Estimate  Std..Error        Lower     Upper\n1    152        0.44435629 0.077789240  0.196796213 0.6919164\n2    153        0.20379664 0.042373512  0.068945217 0.3386481\n3    164        0.50775844 0.047248266  0.357393370 0.6581235\n4    165        0.55839613 0.114195113  0.194976315 0.9218159\n5    169        0.14722311 0.009555688  0.116812646 0.1776336\n6    170        0.37503889 0.043207328  0.237533889 0.5125439\n7    186        0.57975744 0.013332268  0.537328208 0.6221867\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9    188        0.15297172 0.004284691  0.139335920 0.1666075\n10   189        0.53106193 0.023130936  0.457448972 0.6046749\n11 FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n12 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n13 FGT07        0.88770053 0.079917704  0.633366725 1.1420343\n14 FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n15 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n16 FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n17 FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n18 FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n19 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n20 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n\n#Se a ec50 for maior, menos sensível é o isolado (nesse caso ao fungicida)\n\ndf_ec50 |&gt; \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper))+\n  coord_flip()"
  },
  {
    "objectID": "aula10.html#aula-10",
    "href": "aula10.html#aula-10",
    "title": "Análise de correlação",
    "section": "",
    "text": "#install.packages(\"AgroR\")\n\nA correlação é uma relação entre duas ou mais variáveis. Existe uma direção dessa associação, que pode ser forte ou fraca. Ela pode ser linear e positiva. A força da associação está relacionada com a dispersão dos dados, quanto mais disperso os dados mais fraca é a asociação. Então, um dos coeficientes que pode estimar isso é o coeficiente de correlação de Pearson. Quanto mais disperso, mais próximo de zero fica o coeficiente. Ela pode ser negativa quando uma varíaveld diminui em função da outra (ex: produtividade x doença), existindo uma relação de causa/efeito. É usada quando você obtém respostas diferentes e que analisar se existe uma correlação entre as variaveis respostas. Pode ser feita regressão quando o objetivo é predizer y em função de x. Pode chegar em um coeficiente de correlação através de uma análise de regressão, o quanto que a variação de y é explicada pelo x.\nR2 = o quanto da variação de y é explicada pelo x R= a força de associação\n\nlibrary(tidyverse)\nlibrary(gsheet)\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\nimgs |&gt; \n  pivot_longer(3:5, names_to = \"method\", \n               values_to = \"value\") |&gt; \n  ggplot(aes(method, value)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nimgs1 &lt;- imgs |&gt; \n  ggplot(aes(Assess, LeafDoctor)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nimgs1\n\n\n\n\n\n\n\nimgs2 &lt;- imgs |&gt;\n  ggplot(aes(Assess, ImageJ)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") \nimgs2\n\n\n\n\n\n\n\nlibrary(patchwork)\nimgs1 + imgs2\n\n\n\n\n\n\n\n\nEle faz uma matriz de correlação Cor entrega o coeficiente de correlação de pearson. O cor test da uma estatística mais completa. 0,96 é bem próximo de um, então indica uma correlação forte. Quanto maior a correlação menor o p-valor, se os dados forem mais dispersos o p-valor vai ser maior e não vai ser significativo. O corgraph é um pacote que indica a correlação entre as respostas da análise. Os valores dentro da matriz irão indicar o coeficiente de correlação entre as varíaveis observadas.\n\nimgs3 &lt;- imgs |&gt; \n  select(3:5)\n  \nlibrary(AgroR)\ncorgraph(imgs3)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\n\n\n\ncor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\ncor(imgs$Assess, imgs$LeafDoctor)\n\n[1] 0.9666367\n\nlibrary(corrplot)\ncor_imgs2 &lt;- cor(imgs3) \ncorrplot(cor_imgs2, method = \"number\", type = \"lower\", diag = FALSE) \n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\ncampo2 &lt;- campo |&gt; \n  select (DFC, FER, PROD)\nlibrary(AgroR)\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\n\n\n\ncampo |&gt;\n  ggplot(aes(DFC, PROD)) +\n  geom_point()\n\n\n\n\n\n\n\n\nO modelo quadratico é um experimento melhor do que o de primeira ordem, explica melhor o que vemos no gráfico anterior e a variação dos desvios. Pode ser utilizado essa variação, predizer o numero de plantas afetadas. y = (66,3 - 1,77trat) + (0,02trat^2) : equação do modelo\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nestande |&gt;\n  ggplot(aes(trat, nplants, color = factor (exp))) +\n  geom_boxplot() +\n  facet_wrap(~ exp) +\n  theme_bw() +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5,\n               color = \"black\")\n\n\n\n\n\n\n\nestande |&gt;\n  ggplot(aes(trat, nplants, color = factor (exp))) +\n  geom_jitter(width = 0.1, alpha = 0.2) +\n  facet_wrap(~exp) +\n  theme_bw() +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5,\n               color = \"black\") +\n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\nexp2 &lt;- estande |&gt;\n  filter (exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants)) +\n  geom_point() +\n  ylim(0,100) +\n  geom_smooth(method = \"lm\", se = F, formula = y ~poly(x,2), color = \"black\") +\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n\n\n\n\n\n\n\n#MODELO LINEAR\n\nexp2$trat2 &lt;- exp2$trat^2\n\n#primeira ordem\nlm2 &lt;- lm(nplants ~ trat, \n          data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nhist(residuals(lm2))\n\n\n\n\n\n\n\n#segunda ordem\n\nlm3 &lt;- lm(nplants ~ trat + trat2, \n          data = exp2)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\nhist(residuals(lm3))\n\n\n\n\n\n\n\nAIC(lm2)\n\n[1] 194.9597\n\nAIC(lm3)\n\n[1] 193.1284\n\nlibrary(AgroR)\nwith(exp2, polynomial(trat, nplants, grau = 3))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n\n\n[[1]]\n\n\n\n\n\n\n\n\n#library(agro3)\n#data(\"phao\")\n#with(phao, polynomial(dose, comp, grau = 2))\n\n\nlibrary(gsheet)\npyra &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\") \n\nlibrary(tidyverse)\n\npyra |&gt;\n  group_by(code, dose) |&gt;\n  summarise(mean_germination = mean(germination)) |&gt; \n  ggplot(aes(dose, mean_germination)) +\n  geom_point() +\n  facet_wrap(~code) +\n  labs(y = \"Germination\",\n         x = \"Dose\")\n\n\n\n\n\n\n\npyra2 &lt;- pyra |&gt;\n  group_by(code, dose) |&gt;\n  summarise(mean_germination = mean(germination)) \n \nlibrary(drc)\n\nisolado186 &lt;- pyra2 |&gt;\n  filter(code == \"186\")\n\ndrc1 &lt;- drm(mean_germination ~ dose, data = isolado186,\n            fct = LL.3())\nAIC(drc1)\n\n[1] 21.11219\n\nplot(drc1)\n\n\n\n\n\n\n\nED(drc1, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.579757   0.013332 0.537328 0.622187\n\nsummary(drc1)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  4.997636   0.542650  9.2097  0.002708 ** \nd:(Intercept) 48.750109   0.721642 67.5545 7.148e-06 ***\ne:(Intercept)  0.579757   0.013332 43.4853 2.677e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.020525 (3 degrees of freedom)\n\nlibrary(ec50estimator)\n\n\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose, \n                         data = pyra2, \n                         isolate_col = \"code\",\n                         interval = \"delta\", \n                         fct = drc::LL.3())\n\ndf_ec50 |&gt;\n  ggplot(aes(reorder(ID, Estimate), Estimate)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = Lower, ymax= Upper), width = 0.1) +\n  coord_flip()\n\n\n\n\n\n\n\nlibrary(ec50estimator) #Permite estimar o ec50 de todos os isolados ao mesmo tempo\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose,\n                         data = pyra2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\ndf_ec50\n\n      ID strata   Estimate  Std..Error        Lower     Upper\n1    152        0.44435629 0.077789240  0.196796213 0.6919164\n2    153        0.20379664 0.042373512  0.068945217 0.3386481\n3    164        0.50775844 0.047248266  0.357393370 0.6581235\n4    165        0.55839613 0.114195113  0.194976315 0.9218159\n5    169        0.14722311 0.009555688  0.116812646 0.1776336\n6    170        0.37503889 0.043207328  0.237533889 0.5125439\n7    186        0.57975744 0.013332268  0.537328208 0.6221867\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9    188        0.15297172 0.004284691  0.139335920 0.1666075\n10   189        0.53106193 0.023130936  0.457448972 0.6046749\n11 FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n12 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n13 FGT07        0.88770053 0.079917704  0.633366725 1.1420343\n14 FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n15 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n16 FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n17 FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n18 FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n19 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n20 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n\n#Se a ec50 for maior, menos sensível é o isolado (nesse caso ao fungicida)\n\ndf_ec50 |&gt; \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper))+\n  coord_flip()"
  },
  {
    "objectID": "Aula11.html",
    "href": "Aula11.html",
    "title": "Aula 11- Criação de mapas no R",
    "section": "",
    "text": "library(gsheet)\nlibrary(ggplot2)\nlibrary(agricolae)\nlibrary(performance)\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\nlibrary(ggthemes)\nremotes::install_github(\"ropensci/rnaturalearthhires\")\n\nPrimeira camada do geom sf é o país, depois é a camada filtrada com o estado que queremos filtrar.\n\nBRA &lt;- ne_states (country = \"Brazil\",\n                  returnclass = \"sf\")\n\nworld &lt;- ne_countries()\n\nMG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\n\nBA &lt;- BRA |&gt; \n  filter(name_en == \"Bahia\")\n\nlibrary(r4pde)\nsbr &lt;- RustSoybean\nsbr |&gt; \n  ggplot(aes(longitude, latitude)) +\n  geom_point() +\n  coord_sf()\n\n\n\n\n\n\n\nlibrary(ggspatial)\n\nbra &lt;- ggplot(BRA) +\n  geom_sf(fill = \"pink\",\n                      color = \"white\",\n                      linewidth = 1) +\n  geom_sf(data = MG, fill = \"darkgreen\") +\n  geom_sf(data = BA, fill = \"darkgray\") +\n  geom_point( data = sbr, aes(longitude, latitude),\n              color = \"black\") +\n  theme_map() +\n  annotation_north_arrow(which_north = \"grid\")\nbra\n\n\n\n\n\n\n\nlibrary(plotly)\nggplotly(bra)\n\n\n\n\n\n\nlibrary(leaflet)\nvicosa &lt;- leaflet(sbr) |&gt; \n  addTiles() |&gt; \n  #addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt;\n  #setView(lng = -42.8825, lat = -20.7546, zoom = 5) |&gt; \n  addCircleMarkers(radius = 2)\nvicosa\n\n\n\n\n\n\nlibrary(leaflet)\nleaflet(data = BRA) %&gt;% addTiles()\n\n\n\n\n\n\ncf &lt;-leaflet() |&gt; \n  addTiles() |&gt; \n  setView(lng = -40.3224, lat = -10.5113, zoom = 15)\ncf\n\n\n\n\n\n\nmapa &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1pAIFKsdKxk_UQQXdYwIO-O5NOkYNhpclImJcLziYnk4/edit?usp=sharing\")\n\nlibrary(scatterpie)\n#ggplot(BRA) +\n # geom_sf(fill = \"gray80\", alpha = 0.5, color = \"white\") +\n  #coord_sf() +\n  #geom_scatterpie(aes(x=lon, y=lat, r=0.6),\n                  #alpha= 0.8, color = NA, data = mapa, \n                  #cols = c (\"DFC\",\n                            #\"MA\",\n                            #\"FER\",\n                            #\"ANTR\",\n                            #\"OIDIO\")) + \n  #geom_spatial_text_repel( data= mapa, aes(lon, lat, label = Local), \n                          # size = 2, nudge_x = 0.2, nudge_y = 0.27, color = \"gray30\", #family = \"Arial\") +\n  #ggthemes::scale_fill_calc() +\n  #ggthemes::theme_map() +\n  #labs(x = \"Longitude\", y = \"Latitude\", legend = \"\",\n       #fill = \"Doença\") +\n  #theme(legend.position = \"bottom\", text = element_text (family = \"Arial\", size = 8))\n#ggsave(\"mapa.png\", width = 8, height = 8, bg = \"white\")\n\n\nlibrary(ggrepel)\nlibrary(scatterpie)\n\nggplot(BRA) +\n  geom_sf(fill = \"gray70\", alpha = 0.5, color = \"white\") +\n  coord_sf()+\n  geom_scatterpie(aes(x = lon, y = lat, r = 0.6), alpha = 0.8, color = NA, data = mapa,\n                  cols = c(\"DFC\",\n                           \"MA\",\n                           \"FER\",\n                           \"ANTR\",\n                           \"OIDIO\"))+\n  geom_text_repel(data = mapa, aes(lon, lat, label = Local),\n                   size = 2, nudge_x = 0.2, nudge_y = 0.27, color = \"gray30\") +\n  ggthemes::scale_fill_calc()+\n  ggthemes::theme_map() +\n  labs(x = \"Longitude\", y = \"Latitude\", legend = \"\", fill = \"Doença\")+\n  theme(legend.position = \"bottom\", text = element_text(size = 8))"
  },
  {
    "objectID": "Aula11.html#section",
    "href": "Aula11.html#section",
    "title": "Aula 11- Criação de mapas no R",
    "section": "",
    "text": "library(gsheet)\nlibrary(ggplot2)\nlibrary(agricolae)\nlibrary(performance)\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\nlibrary(ggthemes)\nremotes::install_github(\"ropensci/rnaturalearthhires\")\n\nPrimeira camada do geom sf é o país, depois é a camada filtrada com o estado que queremos filtrar.\n\nBRA &lt;- ne_states (country = \"Brazil\",\n                  returnclass = \"sf\")\n\nworld &lt;- ne_countries()\n\nMG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\n\nBA &lt;- BRA |&gt; \n  filter(name_en == \"Bahia\")\n\nlibrary(r4pde)\nsbr &lt;- RustSoybean\nsbr |&gt; \n  ggplot(aes(longitude, latitude)) +\n  geom_point() +\n  coord_sf()\n\n\n\n\n\n\n\nlibrary(ggspatial)\n\nbra &lt;- ggplot(BRA) +\n  geom_sf(fill = \"pink\",\n                      color = \"white\",\n                      linewidth = 1) +\n  geom_sf(data = MG, fill = \"darkgreen\") +\n  geom_sf(data = BA, fill = \"darkgray\") +\n  geom_point( data = sbr, aes(longitude, latitude),\n              color = \"black\") +\n  theme_map() +\n  annotation_north_arrow(which_north = \"grid\")\nbra\n\n\n\n\n\n\n\nlibrary(plotly)\nggplotly(bra)\n\n\n\n\n\n\nlibrary(leaflet)\nvicosa &lt;- leaflet(sbr) |&gt; \n  addTiles() |&gt; \n  #addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt;\n  #setView(lng = -42.8825, lat = -20.7546, zoom = 5) |&gt; \n  addCircleMarkers(radius = 2)\nvicosa\n\n\n\n\n\n\nlibrary(leaflet)\nleaflet(data = BRA) %&gt;% addTiles()\n\n\n\n\n\n\ncf &lt;-leaflet() |&gt; \n  addTiles() |&gt; \n  setView(lng = -40.3224, lat = -10.5113, zoom = 15)\ncf\n\n\n\n\n\n\nmapa &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1pAIFKsdKxk_UQQXdYwIO-O5NOkYNhpclImJcLziYnk4/edit?usp=sharing\")\n\nlibrary(scatterpie)\n#ggplot(BRA) +\n # geom_sf(fill = \"gray80\", alpha = 0.5, color = \"white\") +\n  #coord_sf() +\n  #geom_scatterpie(aes(x=lon, y=lat, r=0.6),\n                  #alpha= 0.8, color = NA, data = mapa, \n                  #cols = c (\"DFC\",\n                            #\"MA\",\n                            #\"FER\",\n                            #\"ANTR\",\n                            #\"OIDIO\")) + \n  #geom_spatial_text_repel( data= mapa, aes(lon, lat, label = Local), \n                          # size = 2, nudge_x = 0.2, nudge_y = 0.27, color = \"gray30\", #family = \"Arial\") +\n  #ggthemes::scale_fill_calc() +\n  #ggthemes::theme_map() +\n  #labs(x = \"Longitude\", y = \"Latitude\", legend = \"\",\n       #fill = \"Doença\") +\n  #theme(legend.position = \"bottom\", text = element_text (family = \"Arial\", size = 8))\n#ggsave(\"mapa.png\", width = 8, height = 8, bg = \"white\")\n\n\nlibrary(ggrepel)\nlibrary(scatterpie)\n\nggplot(BRA) +\n  geom_sf(fill = \"gray70\", alpha = 0.5, color = \"white\") +\n  coord_sf()+\n  geom_scatterpie(aes(x = lon, y = lat, r = 0.6), alpha = 0.8, color = NA, data = mapa,\n                  cols = c(\"DFC\",\n                           \"MA\",\n                           \"FER\",\n                           \"ANTR\",\n                           \"OIDIO\"))+\n  geom_text_repel(data = mapa, aes(lon, lat, label = Local),\n                   size = 2, nudge_x = 0.2, nudge_y = 0.27, color = \"gray30\") +\n  ggthemes::scale_fill_calc()+\n  ggthemes::theme_map() +\n  labs(x = \"Longitude\", y = \"Latitude\", legend = \"\", fill = \"Doença\")+\n  theme(legend.position = \"bottom\", text = element_text(size = 8))"
  },
  {
    "objectID": "aula2_.html",
    "href": "aula2_.html",
    "title": "Aula2 - importar dados e utilizar pacotes",
    "section": "",
    "text": "#Usar os dados de um pacote Para utilizar dados de dentro de um pacote especifico é necessário instalar aquela pacote para que possamos ter acesso aos dados. Você tem que ir na aba “packages” e instalar um novo pacote, procurando na barra de busca. Para usar os dados desse pacote é necessário conhecer a função e o que se quer especificar dentro desse pacote.\n\nlibrary(agricolae)\ndat &lt;- data(corn)\n\n\nlibrary(agridat)\n\nA partir da abertura de dados de um pactoe, é necessário atribuir o seu valor a um objeto, para que depois possamos usar o objeto para trabalhar os valores. Neste exemplo da aula, usamos o objeto df1 para associar os valores da tabela dos dados multi_isolate do pacote escolhido e será a partir desse objeto “df1” que trabalharemos os dados.\n\nlibrary(ec50estimator)\ndf1 &lt;- multi_isolate\n\nPara utilizar os pacotes presentes numa planilha externa ao programa, precisamos usar a biblioteca que utiliza essa função. Nesse caso, é a ‘readxl’, para essa função só podemos utilizar a planilha que está baixada no computador e está no mesmo local, na mesma pasta, que o arquivo da aula. Nesse caso, df2 vai ser a função escolhida para carregar e associar os valores do conjunto de dados. Pode usar também os dados de uma mesma planilha dentro daquele arquivo mas quando ela está em uma outra aba. Ex: planilha do excel com dados de “severidade”, “incidência”, comprimento”… Para abrir a planilha de incidência, usaria a função read_excel(“dados-diversos.xlsx”, sheet = “incidência”).\n\nlibrary(readxl)\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\n\nPara utilizar as planilhas que estãp em csv (separado por ;) precisamos fazer a utilização da biblioteca do tidyverse, que é o pacote que contém essa função.\n\nlibrary(tidyverse)\ndf3 &lt;- read_csv(\"dados-diversos.csv\")\n\nPodemos também utilizar a o link da planilha que está online, basta usar o pacote que abre a planilha google. A função que será utilizada para abrir a planilha é a gsheet2tbl.\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\nPara visualizar os dados, é necessário carregar o pacote responsável pela produção dos gráficos. A varíavel resposta que quer ser observada fica no eixo y. Quando abrir a função do ggplot abaixo do pipe, você deve escolher o que fica no eixo x e no y. O ggplot trabalha em camadas, então na primeira camada você trabalha o aestethic (visual), dai você vai adicionando as camadas com o que você quer adicionar/editar no gráfico. Dentro do geom_jitter você coloca os pontos de dispersão e consegue ajustar a distância que esses pontos vão estar um do outro e “organiza-os” no gráfico com a adição do comando “width”. Quanto mais simétrico está o box, mais normal é a distribuição dos dados. Para colocar a escala do gráfico, você utiliza a função scale_y_continuous colocando o limite de intervalo entre (limits = c (0,20)). O número de quebras da escala do gráfico vai ser colocada com a função n.breaks.\n\nlibrary(ggplot2)\ng1 &lt;- df4 %&gt;%\n  ggplot(aes(trat, comp)) +\n  #geom_point() +\n  geom_boxplot(outlier.colour = NA,\n               fill = \"pink\") +\n  geom_jitter(width = 0.05,\n              color = \"darkblue\",\n              shape = 2,\n              size = 3)\ng1 + theme_classic() +\n  labs(x = \"Tratamento\",\n       y = \"Comprimento (mm)\",\n       title = \"Meu primeiro boxplot\",\n       caption = \"Fonte: Dados diversos\") +\n  scale_y_continuous(limits = c (0,20),\n                     n.breaks = 10)\n\n\n\n\n\n\n\nggsave(\"plot1.png\", bg = \"white\")\n  #ylim(0,20)\n#y.lim(0,20) também funciona para alterar a escala"
  },
  {
    "objectID": "aula5.html",
    "href": "aula5.html",
    "title": "Aula 5- sumariza e criar gráficos",
    "section": "",
    "text": "#Sumarização de dados e apresentação deles Para carregar dados de uma planilha online é necessário abrir o pacote que está dentro da biblioteca gsheet, após isso usa a função gsheet2tbl para puxar os dados da planilha usando um link.\n\nlibrary (gsheet)\nns &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1092065531\")\n\nPrecisamos analisar os valores de média e mediana para entender melhor os dados antes de fazer a visualização deles com o uso do gráfico. Pode ser observado que os valores médio das provas 1 foram de 79,5 com uma mediana de 85,7 e um desvio padrão de 19. Sendo que os valores variavam entre 42,9 e 100 pontos. Para os valores médio das provas 2 foram de 79,26, com uma mediana de 84,37 e um desvio padrão de 19,70. Sendo que os valores variaram de 43,75 até 100 pontos.\n\nlibrary(tidyverse)\nns|&gt;\n  group_by(prova) |&gt; \n  summarise(nota_mean = mean(nota),\n            nota_med = median(nota),\n            nota_sd = sd(nota))\n\n# A tibble: 2 × 4\n  prova nota_mean nota_med nota_sd\n  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1     1      79.5     85.7    19.0\n2     2      79.3     84.4    19.7\n\n\nPara visualizar os dados e comunicá-los em forma de gráfico é necessário abrir a bibilioteca do ggthemes, após isso escolheremos o tipo de gráfico que queremos, nesse primeiro momento, será escolhido o gráfico de histrograma.\n\nlibrary (ggthemes)\nns |&gt;\nggplot (aes(x= nota)) +\ngeom_histogram(bins = 5, fill = \"darkred\", color = \"white\")+\n  facet_wrap(~prova) +\n  scale_fill_colorblind() +\n  theme_bw() +\n  labs(x = \"Nota\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\n#Separação dos dados para criar subconjunto\n\nlibrary(ggplot2)\nnotas1 &lt;- ns |&gt;\n  select(prova, nota) |&gt;\n  filter(prova == 1)\nnotas1\n\n# A tibble: 22 × 2\n   prova  nota\n   &lt;dbl&gt; &lt;dbl&gt;\n 1     1  71.4\n 2     1  92.9\n 3     1  85.7\n 4     1  42.9\n 5     1 100  \n 6     1  85.7\n 7     1 100  \n 8     1  57.1\n 9     1 100  \n10     1  71.4\n# ℹ 12 more rows\n\nnotas2 &lt;- ns |&gt;\n  select(prova, nota) |&gt;\n  filter(prova == 2)\nnotas2\n\n# A tibble: 22 × 2\n   prova  nota\n   &lt;dbl&gt; &lt;dbl&gt;\n 1     2  81.2\n 2     2  68.8\n 3     2  87.5\n 4     2  87.5\n 5     2  87.5\n 6     2 100  \n 7     2 100  \n 8     2 100  \n 9     2 100  \n10     2  43.8\n# ℹ 12 more rows\n\nnotas1 |&gt;\n  count (nota)\n\n# A tibble: 7 × 2\n   nota     n\n  &lt;dbl&gt; &lt;int&gt;\n1  42.9     2\n2  57.1     2\n3  64.3     2\n4  71.4     4\n5  85.7     3\n6  92.9     3\n7 100       6\n\nnotas2|&gt;\n  count(nota)\n\n# A tibble: 6 × 2\n   nota     n\n  &lt;dbl&gt; &lt;int&gt;\n1  43.8     3\n2  56.2     1\n3  68.8     5\n4  81.2     2\n5  87.5     4\n6 100       7\n\n\n#Criação de gráficos separados para cada subconjunto criado\n\nlibrary(ggthemes)\nnotas1 |&gt;\n  ggplot(aes(x = nota)) +\n  geom_histogram(bins = 5, fill = \"darkblue\", color = \"white\") +\n  scale_fill_colorblind() +\n  theme_bw() +\n  labs(title = \"Prova 1\", \n        x = \"Nota\", \n        y= \"Frequency\")\n\n\n\n\n\n\n\nnotas1\n\n# A tibble: 22 × 2\n   prova  nota\n   &lt;dbl&gt; &lt;dbl&gt;\n 1     1  71.4\n 2     1  92.9\n 3     1  85.7\n 4     1  42.9\n 5     1 100  \n 6     1  85.7\n 7     1 100  \n 8     1  57.1\n 9     1 100  \n10     1  71.4\n# ℹ 12 more rows\n\nnotas2 |&gt;\n  ggplot(aes(x = nota)) +\n  geom_histogram(bins = 5, fill = \"darkred\",color = \"white\") +\n  scale_fill_colorblind() +\n  theme_bw() +\n  labs (title = \"Prova 2\",\n        x = \"Nota\", \n        y= \"Frequency\")\n\n\n\n\n\n\n\nnotas2\n\n# A tibble: 22 × 2\n   prova  nota\n   &lt;dbl&gt; &lt;dbl&gt;\n 1     2  81.2\n 2     2  68.8\n 3     2  87.5\n 4     2  87.5\n 5     2  87.5\n 6     2 100  \n 7     2 100  \n 8     2 100  \n 9     2 100  \n10     2  43.8\n# ℹ 12 more rows\n\n\n#Para juntar os gráficos de dois subconjuntos em um único gráfico\n\np1 &lt;- notas1 |&gt;\n  ggplot(aes(x = nota)) +\n  geom_histogram(bins = 5, fill = \"blue\", color = \"White\")  +\n  theme_bw() +\n  labs(title = \"Prova 1\", \n       x = \"Nota\", \n       y = \"Frequency\") +\n  geom_vline(xintercept = 79.54545, linetype = \"dashed\", color = \"red\", size = 1) +\n  ylim(0,10)\n\np2 &lt;- notas2 |&gt; \n  ggplot(aes(x = nota)) +\n  geom_histogram(bins = 5, fill = \"green\", color = \"White\") + \n  theme_bw() +\n  labs(title = \"Prova 2\",\n       x = \"Nota\",\n       y = \"\") +\n  geom_vline(xintercept = 79.26136, linetype = \"dashed\", color = \"red\", size = 1) +\n  ylim(0,10)\n\nlibrary(patchwork)\n(p1 + p2) +\n  plot_layout(guides = \"collect\",\n            axes = \"collect\") \n\n\n\n\n\n\n\n\n#A partir da visualização dos dados, é possível criar quantos gráficos quiser e também se aplicarem ao conjuntos de valores. Para o próximo gráfico, iremos criar um gráfico de boxplot.\n\nlibrary(ggplot2)\nns |&gt; \n  ggplot(aes(factor (prova), nota)) + \n  geom_boxplot(fill = \"purple\") +\n  geom_jitter(width = 0.05)+\n  theme_bw() +\n  labs(x = \"Frequency\",\n       y = \"Provas\")\n\n\n\n\n\n\n\n\n#Quando se tem poucas amotras e tratamentos, pode-se usar o gráfico de pontos com a utilização de um intervalo de confiança para detalhar o intervalo em que as médias utilizadas se encontram.\n\nlibrary(ggplot2)\nns |&gt;\n  group_by(prova) |&gt;\n  summarise(nota_mean = mean(nota),\n            nota_sd = sd(nota)) |&gt;\n  ggplot(aes(factor(prova), nota_mean, color =prova)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = nota_mean - nota_sd, \n                    ymax = nota_mean + nota_sd),\n                width = 0.1) +\n  theme_bw()+\n  theme(legend.position = \"none\") +\n  ylim(0,100) +\n  labs(x = \"Prova\",\n       y= \"Frequency\")"
  },
  {
    "objectID": "Aula8_quarto.html",
    "href": "Aula8_quarto.html",
    "title": "Aula 8- transformações, ANOVA e teste de média",
    "section": "",
    "text": "Para cada variável-resposta será feito um ANOVA. Modificar o ANOVA para considerar o bloco como efeito fixo Temos que modificar o número do tratamento e os números do bloco como fatores.\n\n#theme_set(theme_bw())\nlibrary(tidyverse)\nlibrary(gsheet)\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nsoja &lt;- soja |&gt; \n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))\n\n##Visualizar Gráfico 1 para a variavel DFC Gráfico 2 para a variavel FER Grafico 3 para a variavel PROD\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\") #A bola preta representa a média e a linha o intervalo de confiança\ndfc\n\n\n\n\n\n\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width = 0.1)\nfer\n\n\n\n\n\n\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.1)\nprod\n\n\n\n\n\n\n\nlibrary(patchwork)\ndfc / fer / prod\n\n\n\n\n\n\n\n\n\n\n\nPvalor indicando com *** e o valor super baixo, indiccando que o efeito do tratamento é extremamente significativo. Para blocos, não foi significativo. Pode seguir as análises por que pelo menos uma das médias difere uma da outra, agora temos que saber se podemos confiar na anova e testar as suas premissas de normalidade e homosdasticidade.\n\naov_dfc &lt;- lm(DFC ~ TRAT+BLOCO,  #Bloco entra como efeito fixo ao colocar o \"+\"\n              data = soja)\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Grau de liberdade = n-1\n#F é a divisão entre os Mean Square\n# Trat é extremamente significativo\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\nlibrary(emmeans)\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_dfc, Letters = letters)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  a    \n 7      4.08 0.322 21     3.41     4.74  a    \n 5      4.20 0.322 21     3.53     4.87  a    \n 8      4.58 0.322 21     3.91     5.24  ab   \n 4      4.75 0.322 21     4.08     5.42  ab   \n 3      6.05 0.322 21     5.38     6.72   bc  \n 2      6.42 0.322 21     5.76     7.09    c  \n 1     10.88 0.322 21    10.21    11.54     d \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n#Eficácia no controle (%) = (1- (emmean do tratamento/emmean da testemunha))*100\n\n\n\n\n\naov_fer &lt;- lm(FER ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_fer) #Variância não é homogênea\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\ncheck_normality(aov_fer) #Não há normalidade\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\n#Transformação dos dados\nsoja &lt;- soja |&gt; \n  mutate(FER2 = log(FER))\n\naov_fer2 &lt;- lm(FER2 ~ TRAT+BLOCO,\n               data = soja)\nanova(aov_fer2)\n\nAnalysis of Variance Table\n\nResponse: FER2\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 11.5210 1.64585 42.9665 4.838e-11 ***\nBLOCO      3  0.2064 0.06880  1.7961    0.1788    \nResiduals 21  0.8044 0.03831                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(aov_fer2)\n\nOK: residuals appear as normally distributed (p = 0.255).\n\ncheck_heteroscedasticity(aov_fer2) #Ainda não é homogêneo, mas iremos considerar como homogêneo\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.035).\n\nmedias_fer &lt;- emmeans(aov_fer2, ~ TRAT)\nmedias_fer\n\n TRAT emmean     SE df lower.CL upper.CL\n 1      3.00 0.0979 21    2.793     3.20\n 2      1.74 0.0979 21    1.533     1.94\n 3      1.34 0.0979 21    1.133     1.54\n 4      1.12 0.0979 21    0.921     1.33\n 5      1.18 0.0979 21    0.972     1.38\n 6      1.09 0.0979 21    0.888     1.30\n 7      1.21 0.0979 21    1.011     1.42\n 8      1.25 0.0979 21    1.044     1.45\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer)\n\n        1       2       3       4       5       6       7      8\n1  [3.00]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001 &lt;.0001\n2  1.2600  [1.74]  0.1252  0.0048  0.0110  0.0028  0.0204 0.0343\n3  1.6600  0.4000  [1.34]  0.7832  0.9335  0.6440  0.9843 0.9976\n4  1.8718  0.6118  0.2118  [1.12]  0.9999  1.0000  0.9976 0.9842\n5  1.8211  0.5611  0.1611 -0.0507  [1.18]  0.9984  1.0000 0.9994\n6  1.9052  0.6452  0.2452  0.0334  0.0841  [1.09]  0.9842 0.9431\n7  1.7825  0.5225  0.1226 -0.0893 -0.0385 -0.1227  [1.21] 1.0000\n8  1.7491  0.4891  0.0892 -0.1227 -0.0719 -0.1560 -0.0334 [1.25]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_fer, Letters = letters)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6      1.09 0.0979 21    0.888     1.30  a    \n 4      1.12 0.0979 21    0.921     1.33  a    \n 5      1.18 0.0979 21    0.972     1.38  a    \n 7      1.21 0.0979 21    1.011     1.42  a    \n 8      1.25 0.0979 21    1.044     1.45  a    \n 3      1.34 0.0979 21    1.133     1.54  ab   \n 2      1.74 0.0979 21    1.533     1.94   b   \n 1      3.00 0.0979 21    2.793     3.20    c  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n#Tentando arrumar a normalidade por Lambda\nb &lt;- boxcox(lm(soja$FER ~ 1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\nsoja$FER3 &lt;- (soja$FER ^ lambda - 1)/ lambda\naov_fer3 &lt;- lm(FER3 ~ TRAT+BLOCO,\n              data = soja)\ncheck_normality(aov_fer3)\n\nOK: residuals appear as normally distributed (p = 0.787).\n\ncheck_heteroscedasticity(aov_fer3)\n\nOK: Error variance appears to be homoscedastic (p = 0.872).\n\nmedias_fer2 &lt;- emmeans(aov_fer2, ~ TRAT)\nmedias_fer2\n\n TRAT emmean     SE df lower.CL upper.CL\n 1      3.00 0.0979 21    2.793     3.20\n 2      1.74 0.0979 21    1.533     1.94\n 3      1.34 0.0979 21    1.133     1.54\n 4      1.12 0.0979 21    0.921     1.33\n 5      1.18 0.0979 21    0.972     1.38\n 6      1.09 0.0979 21    0.888     1.30\n 7      1.21 0.0979 21    1.011     1.42\n 8      1.25 0.0979 21    1.044     1.45\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer2)\n\n        1       2       3       4       5       6       7      8\n1  [3.00]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001 &lt;.0001\n2  1.2600  [1.74]  0.1252  0.0048  0.0110  0.0028  0.0204 0.0343\n3  1.6600  0.4000  [1.34]  0.7832  0.9335  0.6440  0.9843 0.9976\n4  1.8718  0.6118  0.2118  [1.12]  0.9999  1.0000  0.9976 0.9842\n5  1.8211  0.5611  0.1611 -0.0507  [1.18]  0.9984  1.0000 0.9994\n6  1.9052  0.6452  0.2452  0.0334  0.0841  [1.09]  0.9842 0.9431\n7  1.7825  0.5225  0.1226 -0.0893 -0.0385 -0.1227  [1.21] 1.0000\n8  1.7491  0.4891  0.0892 -0.1227 -0.0719 -0.1560 -0.0334 [1.25]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_fer2, Letters = letters)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6      1.09 0.0979 21    0.888     1.30  a    \n 4      1.12 0.0979 21    0.921     1.33  a    \n 5      1.18 0.0979 21    0.972     1.38  a    \n 7      1.21 0.0979 21    1.011     1.42  a    \n 8      1.25 0.0979 21    1.044     1.45  a    \n 3      1.34 0.0979 21    1.133     1.54  ab   \n 2      1.74 0.0979 21    1.533     1.94   b   \n 1      3.00 0.0979 21    2.793     3.20    c  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nCom os resultados do CLD pode-se fazer uma tabela com as médias e as letrinhas, também o intervalo de confiança e pode omitir o erro padrão… Ou então uma tabelta mais larga com as 3 variaveis, ou então usar um gráfico e colocar as letras nele. Nunca mostrar a tabela e o gráfico, ai é redundância. ## ANOVA PROD\n\naov_prod &lt;- lm(PROD ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_heteroscedasticity(aov_prod) #Variância é homogênea\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod) #Há normalidade\n\nOK: residuals appear as normally distributed (p = 0.542).\n\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_prod, Letters = letters)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  a    \n 2      4935 201 21     4516     5354  ab   \n 8      5078 201 21     4659     5497  ab   \n 3      5110 201 21     4691     5529  ab   \n 5      5122 201 21     4703     5541  ab   \n 7      5128 201 21     4709     5546  ab   \n 4      5140 201 21     4721     5559  ab   \n 6      5256 201 21     4837     5675   b   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nmedias_prod_grupo &lt;- cld(medias_prod, Letters = letters)\n\nOutra forma de visualizar os valores da produtividade\n\ndf_prod &lt;- data.frame(medias_prod_grupo)\ndf_prod |&gt; \n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.1)+\n  annotate(geom = \"text\", x = 1.1, y = 4200, label = \"A\")+\n  annotate(geom = \"text\", x = 2.1, y = 5000, label = \"AB\")\n\n\n\n\n\n\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\na\n\n\n2\n2\n4935.00\nab\n\n\n8\n8\n5078.25\nab\n\n\n3\n3\n5110.00\nab\n\n\n5\n5\n5122.00\nab\n\n\n7\n7\n5127.50\nab\n\n\n4\n4\n5140.25\nab\n\n\n6\n6\n5256.25\nb\n\n\n\n\nlibrary(writexl)\nwrite_xlsx(df_prod, \"df.xlsx\")\n\n#Diferença de produtividade = emmean do tratamento - emmean da testemunha\n\nSe quiser colocar as letrinhas, tem que usar o anotate e fazer a “colocação” manualmente. Os dados 1 e 6 não tem overleap do intervlao de confiança, já os que tem o overleap ex 1 e 5 estão no mesmo grupo e não diferem estatisticamente. É uma maneira visual de determinar a diferença e fazer o leitor entender."
  },
  {
    "objectID": "Aula8_quarto.html#importa-dados",
    "href": "Aula8_quarto.html#importa-dados",
    "title": "Aula 8- transformações, ANOVA e teste de média",
    "section": "",
    "text": "Para cada variável-resposta será feito um ANOVA. Modificar o ANOVA para considerar o bloco como efeito fixo Temos que modificar o número do tratamento e os números do bloco como fatores.\n\n#theme_set(theme_bw())\nlibrary(tidyverse)\nlibrary(gsheet)\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nsoja &lt;- soja |&gt; \n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))\n\n##Visualizar Gráfico 1 para a variavel DFC Gráfico 2 para a variavel FER Grafico 3 para a variavel PROD\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC))+\n  geom_jitter(width = 0.05, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\") #A bola preta representa a média e a linha o intervalo de confiança\ndfc\n\n\n\n\n\n\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width = 0.1)\nfer\n\n\n\n\n\n\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.1)\nprod\n\n\n\n\n\n\n\nlibrary(patchwork)\ndfc / fer / prod"
  },
  {
    "objectID": "Aula8_quarto.html#anova-dfc",
    "href": "Aula8_quarto.html#anova-dfc",
    "title": "Aula 8- transformações, ANOVA e teste de média",
    "section": "",
    "text": "Pvalor indicando com *** e o valor super baixo, indiccando que o efeito do tratamento é extremamente significativo. Para blocos, não foi significativo. Pode seguir as análises por que pelo menos uma das médias difere uma da outra, agora temos que saber se podemos confiar na anova e testar as suas premissas de normalidade e homosdasticidade.\n\naov_dfc &lt;- lm(DFC ~ TRAT+BLOCO,  #Bloco entra como efeito fixo ao colocar o \"+\"\n              data = soja)\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Grau de liberdade = n-1\n#F é a divisão entre os Mean Square\n# Trat é extremamente significativo\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\nlibrary(emmeans)\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_dfc, Letters = letters)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  a    \n 7      4.08 0.322 21     3.41     4.74  a    \n 5      4.20 0.322 21     3.53     4.87  a    \n 8      4.58 0.322 21     3.91     5.24  ab   \n 4      4.75 0.322 21     4.08     5.42  ab   \n 3      6.05 0.322 21     5.38     6.72   bc  \n 2      6.42 0.322 21     5.76     7.09    c  \n 1     10.88 0.322 21    10.21    11.54     d \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n#Eficácia no controle (%) = (1- (emmean do tratamento/emmean da testemunha))*100"
  },
  {
    "objectID": "Aula8_quarto.html#anova-fer",
    "href": "Aula8_quarto.html#anova-fer",
    "title": "Aula 8- transformações, ANOVA e teste de média",
    "section": "",
    "text": "aov_fer &lt;- lm(FER ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_fer) #Variância não é homogênea\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\ncheck_normality(aov_fer) #Não há normalidade\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\n#Transformação dos dados\nsoja &lt;- soja |&gt; \n  mutate(FER2 = log(FER))\n\naov_fer2 &lt;- lm(FER2 ~ TRAT+BLOCO,\n               data = soja)\nanova(aov_fer2)\n\nAnalysis of Variance Table\n\nResponse: FER2\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 11.5210 1.64585 42.9665 4.838e-11 ***\nBLOCO      3  0.2064 0.06880  1.7961    0.1788    \nResiduals 21  0.8044 0.03831                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(aov_fer2)\n\nOK: residuals appear as normally distributed (p = 0.255).\n\ncheck_heteroscedasticity(aov_fer2) #Ainda não é homogêneo, mas iremos considerar como homogêneo\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.035).\n\nmedias_fer &lt;- emmeans(aov_fer2, ~ TRAT)\nmedias_fer\n\n TRAT emmean     SE df lower.CL upper.CL\n 1      3.00 0.0979 21    2.793     3.20\n 2      1.74 0.0979 21    1.533     1.94\n 3      1.34 0.0979 21    1.133     1.54\n 4      1.12 0.0979 21    0.921     1.33\n 5      1.18 0.0979 21    0.972     1.38\n 6      1.09 0.0979 21    0.888     1.30\n 7      1.21 0.0979 21    1.011     1.42\n 8      1.25 0.0979 21    1.044     1.45\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer)\n\n        1       2       3       4       5       6       7      8\n1  [3.00]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001 &lt;.0001\n2  1.2600  [1.74]  0.1252  0.0048  0.0110  0.0028  0.0204 0.0343\n3  1.6600  0.4000  [1.34]  0.7832  0.9335  0.6440  0.9843 0.9976\n4  1.8718  0.6118  0.2118  [1.12]  0.9999  1.0000  0.9976 0.9842\n5  1.8211  0.5611  0.1611 -0.0507  [1.18]  0.9984  1.0000 0.9994\n6  1.9052  0.6452  0.2452  0.0334  0.0841  [1.09]  0.9842 0.9431\n7  1.7825  0.5225  0.1226 -0.0893 -0.0385 -0.1227  [1.21] 1.0000\n8  1.7491  0.4891  0.0892 -0.1227 -0.0719 -0.1560 -0.0334 [1.25]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_fer, Letters = letters)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6      1.09 0.0979 21    0.888     1.30  a    \n 4      1.12 0.0979 21    0.921     1.33  a    \n 5      1.18 0.0979 21    0.972     1.38  a    \n 7      1.21 0.0979 21    1.011     1.42  a    \n 8      1.25 0.0979 21    1.044     1.45  a    \n 3      1.34 0.0979 21    1.133     1.54  ab   \n 2      1.74 0.0979 21    1.533     1.94   b   \n 1      3.00 0.0979 21    2.793     3.20    c  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n#Tentando arrumar a normalidade por Lambda\nb &lt;- boxcox(lm(soja$FER ~ 1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\nsoja$FER3 &lt;- (soja$FER ^ lambda - 1)/ lambda\naov_fer3 &lt;- lm(FER3 ~ TRAT+BLOCO,\n              data = soja)\ncheck_normality(aov_fer3)\n\nOK: residuals appear as normally distributed (p = 0.787).\n\ncheck_heteroscedasticity(aov_fer3)\n\nOK: Error variance appears to be homoscedastic (p = 0.872).\n\nmedias_fer2 &lt;- emmeans(aov_fer2, ~ TRAT)\nmedias_fer2\n\n TRAT emmean     SE df lower.CL upper.CL\n 1      3.00 0.0979 21    2.793     3.20\n 2      1.74 0.0979 21    1.533     1.94\n 3      1.34 0.0979 21    1.133     1.54\n 4      1.12 0.0979 21    0.921     1.33\n 5      1.18 0.0979 21    0.972     1.38\n 6      1.09 0.0979 21    0.888     1.30\n 7      1.21 0.0979 21    1.011     1.42\n 8      1.25 0.0979 21    1.044     1.45\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer2)\n\n        1       2       3       4       5       6       7      8\n1  [3.00]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001 &lt;.0001\n2  1.2600  [1.74]  0.1252  0.0048  0.0110  0.0028  0.0204 0.0343\n3  1.6600  0.4000  [1.34]  0.7832  0.9335  0.6440  0.9843 0.9976\n4  1.8718  0.6118  0.2118  [1.12]  0.9999  1.0000  0.9976 0.9842\n5  1.8211  0.5611  0.1611 -0.0507  [1.18]  0.9984  1.0000 0.9994\n6  1.9052  0.6452  0.2452  0.0334  0.0841  [1.09]  0.9842 0.9431\n7  1.7825  0.5225  0.1226 -0.0893 -0.0385 -0.1227  [1.21] 1.0000\n8  1.7491  0.4891  0.0892 -0.1227 -0.0719 -0.1560 -0.0334 [1.25]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_fer2, Letters = letters)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6      1.09 0.0979 21    0.888     1.30  a    \n 4      1.12 0.0979 21    0.921     1.33  a    \n 5      1.18 0.0979 21    0.972     1.38  a    \n 7      1.21 0.0979 21    1.011     1.42  a    \n 8      1.25 0.0979 21    1.044     1.45  a    \n 3      1.34 0.0979 21    1.133     1.54  ab   \n 2      1.74 0.0979 21    1.533     1.94   b   \n 1      3.00 0.0979 21    2.793     3.20    c  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nCom os resultados do CLD pode-se fazer uma tabela com as médias e as letrinhas, também o intervalo de confiança e pode omitir o erro padrão… Ou então uma tabelta mais larga com as 3 variaveis, ou então usar um gráfico e colocar as letras nele. Nunca mostrar a tabela e o gráfico, ai é redundância. ## ANOVA PROD\n\naov_prod &lt;- lm(PROD ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_heteroscedasticity(aov_prod) #Variância é homogênea\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod) #Há normalidade\n\nOK: residuals appear as normally distributed (p = 0.542).\n\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_prod, Letters = letters)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  a    \n 2      4935 201 21     4516     5354  ab   \n 8      5078 201 21     4659     5497  ab   \n 3      5110 201 21     4691     5529  ab   \n 5      5122 201 21     4703     5541  ab   \n 7      5128 201 21     4709     5546  ab   \n 4      5140 201 21     4721     5559  ab   \n 6      5256 201 21     4837     5675   b   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nmedias_prod_grupo &lt;- cld(medias_prod, Letters = letters)\n\nOutra forma de visualizar os valores da produtividade\n\ndf_prod &lt;- data.frame(medias_prod_grupo)\ndf_prod |&gt; \n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.1)+\n  annotate(geom = \"text\", x = 1.1, y = 4200, label = \"A\")+\n  annotate(geom = \"text\", x = 2.1, y = 5000, label = \"AB\")\n\n\n\n\n\n\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\na\n\n\n2\n2\n4935.00\nab\n\n\n8\n8\n5078.25\nab\n\n\n3\n3\n5110.00\nab\n\n\n5\n5\n5122.00\nab\n\n\n7\n7\n5127.50\nab\n\n\n4\n4\n5140.25\nab\n\n\n6\n6\n5256.25\nb\n\n\n\n\nlibrary(writexl)\nwrite_xlsx(df_prod, \"df.xlsx\")\n\n#Diferença de produtividade = emmean do tratamento - emmean da testemunha\n\nSe quiser colocar as letrinhas, tem que usar o anotate e fazer a “colocação” manualmente. Os dados 1 e 6 não tem overleap do intervlao de confiança, já os que tem o overleap ex 1 e 5 estão no mesmo grupo e não diferem estatisticamente. É uma maneira visual de determinar a diferença e fazer o leitor entender."
  },
  {
    "objectID": "aula_04.html",
    "href": "aula_04.html",
    "title": "Aula 4 - criação de dataframe e configuração dos dados",
    "section": "",
    "text": "comp &lt;- c(9, 125, 10, 8, 132, 11, 108, 95, 108, 104, 1372, 1591, 157, 142, 159, 1654, 18, 144, 1641, 16)"
  },
  {
    "objectID": "aula_04.html#conjunto-de-dados",
    "href": "aula_04.html#conjunto-de-dados",
    "title": "Aula 4 - criação de dataframe e configuração dos dados",
    "section": "",
    "text": "comp &lt;- c(9, 125, 10, 8, 132, 11, 108, 95, 108, 104, 1372, 1591, 157, 142, 159, 1654, 18, 144, 1641, 16)"
  },
  {
    "objectID": "aula_04.html#pacotes",
    "href": "aula_04.html#pacotes",
    "title": "Aula 4 - criação de dataframe e configuração dos dados",
    "section": "Pacotes",
    "text": "Pacotes\n\nlibrary(tidyverse)\nlibrary(tibble)\nlibrary(data.table)\nlibrary(pak)\n\nColando através do comando “Data pasta” (um data frame) um conjunto de dados de uma tabela.\n\ndat &lt;- data.frame(stringsAsFactors = FALSE,\n                      trat = c(\"Mg2\",\"Mg2\",\n                               \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                               \"Mg2\",\"control\",\"control\",\"control\",\"control\",\n                               \"control\",\"control\",\"control\",\"control\",\n                               \"control\",\"control\"),\n                       rep = c(1L,2L,3L,4L,\n                               5L,6L,7L,8L,9L,10L,1L,2L,3L,4L,5L,6L,\n                               7L,8L,9L,10L),\n                      comp = c(9,125,10,8,\n                               132,11,108,95,108,104,1372,1591,157,142,\n                               159,1654,18,144,1641,16))\n\n\ndat2 &lt;- tibble::tribble(\n         ~trat, ~rep, ~comp,\n         \"Mg2\",   1L,     9,\n         \"Mg2\",   2L,   125,\n         \"Mg2\",   3L,    10,\n         \"Mg2\",   4L,     8,\n         \"Mg2\",   5L,   132,\n         \"Mg2\",   6L,    11,\n         \"Mg2\",   7L,   108,\n         \"Mg2\",   8L,    95,\n         \"Mg2\",   9L,   108,\n         \"Mg2\",  10L,   104,\n     \"control\",   1L,  1372,\n     \"control\",   2L,  1591,\n     \"control\",   3L,   157,\n     \"control\",   4L,   142,\n     \"control\",   5L,   159,\n     \"control\",   6L,  1654,\n     \"control\",   7L,    18,\n     \"control\",   8L,   144,\n     \"control\",   9L,  1641,\n     \"control\",  10L,    16)"
  },
  {
    "objectID": "aula_04.html#crianto-tabelas-a-partir-de-dados",
    "href": "aula_04.html#crianto-tabelas-a-partir-de-dados",
    "title": "Aula 4 - criação de dataframe e configuração dos dados",
    "section": "Crianto tabelas a partir de dados",
    "text": "Crianto tabelas a partir de dados\nImportando tabelas da internet usando a função “addins”, “paste as tribble”.\n\nestados &lt;- tibble::tribble(\n                          ~Cidade,               ~Região,  ~Habitantes,\n             \"Brasília / Capital\",    \"Distrito Federal\",  \"2.912.000\",\n                      \"São Paulo\",           \"São Paulo\", \"12.400.000\",\n                 \"Rio de Janeiro\",      \"Rio de Janeiro\",  \"6.748.000\",\n                      \"Fortaleza\",               \"Ceará\",  \"2.669.000\",\n                 \"Belo Horizonte\",        \"Minas Gerais\",  \"2.512.000\",\n                       \"Salvador\",               \"Bahia\",  \"2.418.000\",\n                         \"Manaus\",            \"Amazonas\",  \"2.220.000\",\n                       \"Curitiba\",              \"Paraná\",  \"1.964.000\",\n                         \"Recife\",          \"Pernambuco\",  \"1.653.000\",\n                        \"Goiânia\",               \"Goiás\",  \"1.536.000\",\n                          \"Belém\",                \"Pará\",  \"1.500.000\",\n                   \"Porto Alegre\",   \"Rio Grande do Sul\",  \"1.488.000\",\n                      \"Guarulhos\",           \"São Paulo\",  \"1.292.000\",\n                       \"Campinas\",           \"São Paulo\",  \"1.139.000\",\n                       \"São Luís\",            \"Maranhão\",  \"1.041.000\",\n                         \"Maceió\",             \"Alagoas\",  \"1.018.000\",\n                          \"Natal\", \"Rio Grande do Norte\",    \"884.000\",\n                   \"Campo Grande\",  \"Mato Grosso do Sul\",    \"884.000\",\n                       \"Teresina\",               \"Piauí\",    \"815.000\",\n                    \"João Pessoa\",             \"Paraíba\",    \"806.000\",\n                        \"Aracaju\",             \"Sergipe\",    \"571.000\",\n                    \"Porto Velho\",            \"Rondônia\",    \"483.000\",\n                  \"Florianópolis\",      \"Santa Catarina\",    \"482.000\",\n                         \"Macapá\",               \"Amapá\",    \"482.000\",\n                     \"Rio Branco\",                \"Acre\",    \"309.000\",\n                         \"Palmas\",           \"Tocantins\",    \"306.000\",\n                      \"Boa Vista\",             \"Roraima\",    \"278.000\",\n                         \"Cuiabá\",         \"Mato Grosso\",    \"221.000\",\n                        \"Vitória\",      \"Espírito Santo\",    \"212.000\")\n\nDados dispostos em formato largo em 3 colunas diferentes. Para trabalharmos esses dados, é interessante que trabalhemos no formato longo, portanto, devemos adicionar todos em uma só coluna, transformando em data frame.\n\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74) \n\nPivot longer consegue transformar os dados do formato largo para o formato longo, para que possamos fazer um ggplot. Trabalhar com os dados em formato longo é muitas vezes preferível no R, especialmente ao utilizar os pacotes como tidyverse.\n\npepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"Epidemic\",\n               values_to = \"inc\")\n\n# A tibble: 24 × 3\n       t Epidemic   inc\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     0 1        0.08 \n 2     0 2        0.001\n 3     0 3        0.001\n 4     7 1        0.13 \n 5     7 2        0.01 \n 6     7 3        0.001\n 7    14 1        0.78 \n 8    14 2        0.09 \n 9    14 3        0.01 \n10    21 1        0.92 \n# ℹ 14 more rows\n\n\nCriação de gráficos de linhas com pontos. Gráficos de linhas com pontos são utilizados para visualizar dados ao longo do tempo ou outras variáveis contínuas. Eles combinam as características de gráficos de linhas e gráficos de dispersão, destacando tanto as tendências gerais quando os pontos de dados individuais.\n\npepper |&gt; \n  pivot_longer(2:4, names_to = 'epidemic', \n               values_to = 'inc') |&gt; \n  ggplot(aes(t, inc, color = epidemic)) +\n  geom_point() + \n  geom_line() + \n  annotate(geom = 'text',\n           x = 10,\n           y = 0.75,\n           label = '1') +\n  annotate(geom = 'text',\n         x = 25,\n         y = 0.75,\n         label = '2') +\n  annotate(geom = 'text',\n           x = 45,\n           y = 0.75,\n           label = '3')"
  },
  {
    "objectID": "aula_04.html#aula-04---parte-02",
    "href": "aula_04.html#aula-04---parte-02",
    "title": "Aula 4 - criação de dataframe e configuração dos dados",
    "section": "Aula 04 - Parte 02",
    "text": "Aula 04 - Parte 02\n\nlibrary(janitor)\nlibrary(ggthemes)\nlibrary(gsheet)\n\n\nImportação de dados de planilha\nFormato .csv.\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\ncr\n\n# A tibble: 405 × 13\n    farm region zone       district      lon   lat altitude cultivar shade    \n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    \n 1     1 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n 2     2 SNNPR  Bench Maji Debub Bench  35.4  6.90     1342 Mixture  Mid shade\n 3     3 SNNPR  Bench Maji Debub Bench  35.4  6.90     1434 Mixture  Mid shade\n 4     4 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n 5     5 SNNPR  Bench Maji Debub Bench  35.4  6.90     1400 Local    Sun      \n 6     6 SNNPR  Bench Maji Debub Bench  35.4  6.90     1342 Mixture  Mid shade\n 7     7 SNNPR  Bench Maji Debub Bench  35.4  6.90     1432 Mixture  Mid shade\n 8     8 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n 9     9 SNNPR  Bench Maji Debub Bench  35.4  6.89     1400 Local    Sun      \n10    10 SNNPR  Bench Maji Debub Bench  35.4  6.88     1342 Mixture  Mid shade\n# ℹ 395 more rows\n# ℹ 4 more variables: cropping_system &lt;chr&gt;, farm_management &lt;chr&gt;, inc &lt;dbl&gt;,\n#   sev2 &lt;dbl&gt;\n\n\nRealizando a contagem do número de observações do conjunto de dados.\n\ncr |&gt; \n  count(region, zone)\n\n# A tibble: 9 × 3\n  region zone             n\n  &lt;chr&gt;  &lt;chr&gt;        &lt;int&gt;\n1 Oromia Bale            30\n2 Oromia Ilu AbaBora     45\n3 Oromia Jimma           45\n4 Oromia West Wellega    45\n5 SNNPR  Bench Maji      45\n6 SNNPR  Gedio           45\n7 SNNPR  Keffa           45\n8 SNNPR  Sheka           45\n9 SNNPR  Sidama          60\n\n\nCriando uma tabela com tabulações cruzadas em formato data frame tibble.\n\ncr |&gt; \n  tabyl(cultivar, region)\n\n cultivar Oromia SNNPR\n Improved     23    60\n    Local     50    66\n  Mixture     92   114\n\n\nCriando gráficos de coluna. Faz o empilhamento das colunas. Padrão steck.\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col()\n\n\n\n\n\n\n\n\nGráfico de barras lado a lado. Alterando a posição (dodge)\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col(position = \"dodge\")\n\n\n\n\n\n\n\n\nAlterando as cores.\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col(position = \"dodge\") +\n  scale_fill_calc()+\n  facet_wrap(~cultivar, scales = \"free_x\")\n\n\n\n\n\n\n\n\nAdicionando os valores sobre as colunas do gráfico.\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management, label = n))+\n  geom_col(position = \"dodge\") +\n  scale_fill_calc()+\n  theme_bw()+\n  theme(strip.text.x = element_blank(),\n        legend.position = \"top\")+\n  geom_text(position = position_dodge(width = 0.9))+\n  facet_wrap(~cultivar, scales = \"free_x\")\n\n\n\n\n\n\n\n\nImportando dados de planilha online.\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit?usp=sharing\")\nmg\n\n# A tibble: 20 × 3\n   trat      rep  comp\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Mg2         1   9  \n 2 Mg2         2  12.5\n 3 Mg2         3  10  \n 4 Mg2         4   8  \n 5 Mg2         5  13.2\n 6 Mg2         6  11  \n 7 Mg2         7  10.8\n 8 Mg2         8   9.5\n 9 Mg2         9  10.8\n10 Mg2        10  10.4\n11 control     1  13.7\n12 control     2  15.9\n13 control     3  15.7\n14 control     4  14.2\n15 control     5  15.9\n16 control     6  16.5\n17 control     7  18  \n18 control     8  14.4\n19 control     9  16.4\n20 control    10  16  \n\n\nCriando gráficos de colunas com médias e desvio padrão.\n\nmg |&gt;\n  group_by(trat) |&gt; \n  summarise(mean_comp = mean(comp), sd_comp = sd(comp)) |&gt; \n  ggplot(aes(trat, mean_comp))+\n  geom_col(fill = \"steelblue\", width = 0.5)+\n  geom_errorbar(aes(ymin = mean_comp - sd_comp,\n                    ymax = mean_comp + sd_comp),\n                width = 0.1)\n\n\n\n\n\n\n\n\nPara remover a coluna do gráfico, basta isolar a linha de comando. Não é necessário manter a coluna.\n\nmg |&gt;\n  group_by(trat) |&gt; \n  summarise(mean_comp = mean(comp), sd_comp = sd(comp)) |&gt; \n  ggplot(aes(trat, mean_comp))+\n  #geom_col(fill = \"steelblue\", width = 0.5)+\n  geom_errorbar(aes(ymin = mean_comp - sd_comp,\n                    ymax = mean_comp + sd_comp),\n                width = 0.1)\n\n\n\n\n\n\n\n\n\nmg |&gt; \n  group_by(trat) |&gt; \n    summarise(mean_comp = mean(comp), \n              sd_comp = sd(comp)) |&gt; \n    ggplot(aes(trat, mean_comp)) + \n    #geom_col(fill = 'red', width = 0.5) +\n    geom_point(size = 3) +\n    ylim(5, 20) +\n    geom_errorbar(aes(ymin = mean_comp - sd_comp, \n                      ymax = mean_comp + sd_comp), \n                  width = 0.05) +\n    annotate(geom = 'text',\n           x = 1, y = 17.5,\n           label = \"*\")"
  }
]